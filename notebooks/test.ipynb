{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Z:\\OMOP\\omop_etl\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sqlparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "os.chdir('Z:\\OMOP\\omop_etl')\n",
    "print(os.getcwd())\n",
    "\n",
    "from omop_etl.datastore import DataStore, format_bo_sql\n",
    "from omop_etl.load import Loader\n",
    "from omop_etl.utils import search\n",
    "\n",
    "# Generate cohort\n",
    "omop = DataStore('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "omop = DataStore('config.yml')\n",
    "\n",
    "def format_stage_query(dp_name):\n",
    "\n",
    "    with open('omop_etl/etl_config.yml') as f:\n",
    "        yml = yaml.safe_load(f) \n",
    "    \n",
    "    aliases= yml['aliases'][dp_name]\n",
    "    bo_queries = omop.get_bo_query('omop')\n",
    "\n",
    "    start_date = omop.config_param['date_range']['start_date']\n",
    "    end_date = omop.config_param['date_range']['end_date']\n",
    "\n",
    "    sql_query = format_bo_sql(bo_queries[dp_name], dp_name, schema='stage', aliases=aliases)\n",
    "    patient_id = \"select PATIENT_KEY from DWS_OMOP.cohort.PersonList\"\n",
    "    sql_query = sql_query.replace(\"12345678\", patient_id)\n",
    "    sql_query = sql_query.replace(\"01/01/1900 00:0:0\", start_date)\n",
    "    sql_query = sql_query.replace(\"12/31/1900 00:0:0\", end_date)\n",
    "\n",
    "    sql_query = sqlparse.format(sql_query, reindent_aligned=True, indent_with=1)\n",
    "\n",
    "    return f\"EXECUTE ('USE [DWS_PROD];\\n {sql_query}')\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "bo_queries = omop.get_bo_query('cohort_COVID_Broad')\n",
    "len(bo_queries.keys())\n",
    "# [q for q in bo_queries.keys() if bo_queries[q] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['CPT_CodingDetail', 'ICD_CodingDetail', 'Labs_UFHealth', 'Meds_by_name'])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "bo_queries.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo_queries[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"SELECT  dbo.ALL_PATIENTS.PATNT_KEY,  dbo.ALL_PATIENTS.PATNT_ID,  Table__1308.IDENT_ID_INT,  Table__1117.IDENT_ID_INT,  PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY FROM  dbo.ALL_PROCEDURES RIGHT OUTER JOIN dbo.ORDER_PROCEDURE_DTL ON (dbo.ALL_PROCEDURES.PROC_KEY=dbo.ORDER_PROCEDURE_DTL.PROC_KEY)  RIGHT OUTER JOIN dbo.PATIENT_ENCOUNTER_DTL ON (dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=dbo.ORDER_PROCEDURE_DTL.PATNT_ENCNTR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND='N'\\r )  LEFT OUTER JOIN dbo.ALL_PATIENT_SNAPSHOTS ALL_PT_SNAPSHOTS_ENCOUNTER ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_SNAPSHT_KEY=dbo.PATIENT_ENCOUNTER_DTL.DSCHRG_PATNT_SNAPSHT_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND='N'\\r )  LEFT OUTER JOIN dbo.ALL_PATIENTS ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_KEY=dbo.ALL_PATIENTS.PATNT_KEY)  LEFT OUTER JOIN (  SELECT * \\r FROM \\r  dbo.ALL_PATIENT_IDENTITIES \\r WHERE\\r  dbo.ALL_PATIENT_IDENTITIES.LOOKUP_IND = 'Y'\\r AND\\r  dbo.ALL_PATIENT_IDENTITIES.IDENT_ID_TYPE = 110  ) Table__1117 ON (Table__1117.PATNT_KEY=ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_KEY)  LEFT OUTER JOIN (  SELECT * \\r FROM \\r  dbo.ALL_PATIENT_IDENTITIES \\r WHERE\\r  dbo.ALL_PATIENT_IDENTITIES.LOOKUP_IND = 'Y'\\r AND\\r  dbo.ALL_PATIENT_IDENTITIES.IDENT_ID_TYPE = 101  ) Table__1308 ON (Table__1308.PATNT_KEY=ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_KEY)  LEFT OUTER JOIN dbo.PATNT_ENCNTR_KEY_XREF PATNT_ENCNTR_KEY_XREF1 ON (dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND='N'\\r )  LEFT OUTER JOIN dbo.LAB_RESULT_DTL ON (dbo.LAB_RESULT_DTL.ORDR_PROC_KEY=dbo.ORDER_PROCEDURE_DTL.ORDR_PROC_KEY)  LEFT OUTER JOIN dbo.ALL_LABS ALL_LABS1 ON (dbo.LAB_RESULT_DTL.LAB_KEY=ALL_LABS1.LAB_KEY)  WHERE  (  (   Table__1117.IDENT_ID_INT Is Not Null    OR   Table__1308.IDENT_ID_INT Is Not Null   )  AND  ALL_LABS1.LAB_ID IN ( 10518, 12350000, 12350002 )  AND  ( dbo.ALL_PROCEDURES.PROC_CD ) IN ( 'LAB17003','LAB17006','LAB17007','LAB17008','LAB17009','LAB4636','LAB4636A','LAB4637','LAB4639','LAB4642' )  AND  ( dbo.ORDER_PROCEDURE_DTL.ORDR_PLACE_DATE ) >= '01/01/2020 00:0:0'  AND  ( dbo.ALL_PATIENTS.TEST_IND='N' )  )\""
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "table = 'Labs_UFHealth'\n",
    "# print(format_stage_query(table))\n",
    "bo_queries[table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CONDITION\n",
      "DEATH\n",
      "DRUG_ADMIN\n",
      "DRUG_ORDER\n",
      "MEASUREMENT_BP_ArterialLine\n",
      "MEASUREMENT_BP_BP\n",
      "MEASUREMENT_BP_BP_NonInvasive\n",
      "MEASUREMENT_BP_CVP\n",
      "MEASUREMENT_BP_CVP_mean\n",
      "MEASUREMENT_BP_MAP_A_line\n",
      "MEASUREMENT_BP_MAP_Cuff\n",
      "MEASUREMENT_BP_MAP_NonINvasive\n",
      "MEASUREMENT_BP_PAP_mean\n",
      "MEASUREMENT_HeartRate\n",
      "MEASUREMENT_Height\n",
      "MEASUREMENT_LAB\n",
      "MEASUREMENT_PainScale\n",
      "MEASUREMENT_PainScale_JAX\n",
      "MEASUREMENT_PainScale_Peds\n",
      "MEASUREMENT_QTCB\n",
      "MEASUREMENT_Res_Device\n",
      "MEASUREMENT_Res_ETCO2\n",
      "MEASUREMENT_Res_ETCO2_NO\n",
      "MEASUREMENT_Res_FIO2\n",
      "MEASUREMENT_Res_GCS\n",
      "MEASUREMENT_Res_GCS_Peds\n",
      "MEASUREMENT_Res_O2\n",
      "MEASUREMENT_Res_O2_mL\n",
      "MEASUREMENT_Res_PEEP\n",
      "MEASUREMENT_Res_PIP\n",
      "MEASUREMENT_Res_RESP\n",
      "MEASUREMENT_Res_RESP_AdultMech\n",
      "MEASUREMENT_Res_RESP_AdultSpont\n",
      "MEASUREMENT_Res_RESP_PedsMech\n",
      "MEASUREMENT_Res_RESP_PedsSpont\n",
      "MEASUREMENT_Res_SPO2\n",
      "MEASUREMENT_Res_Tidal\n",
      "MEASUREMENT_Res_TidalExhaled\n",
      "MEASUREMENT_Res_Vent\n",
      "MEASUREMENT_Res_VentPeds\n",
      "MEASUREMENT_Rothman\n",
      "MEASUREMENT_SOFA\n",
      "MEASUREMENT_Temp\n",
      "MEASUREMENT_Weight\n",
      "OBSERVATION_ICU\n",
      "OBSERVATION_LDA\n",
      "OBSERVATION_Payer\n",
      "OBSERVATION_Smoking\n",
      "OBSERVATION_Vent\n",
      "OBSERVATION_Zipcode\n",
      "PERSON\n",
      "PROCEDURE_CPT\n",
      "PROCEDURE_ICD\n",
      "VISIT\n"
     ]
    }
   ],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "# print(bo_queries.keys())\n",
    "\n",
    "# SAVE QUERIES TO FILE\n",
    "for t in bo_queries.keys():\n",
    "    try:\n",
    "        print(t)\n",
    "        f = open(f'./output/sqlstring_{t.lower()}.sql', 'w')\n",
    "        f.write(format_stage_query(t))\n",
    "        format_stage_query(t)\n",
    "        f.close()\n",
    "    except ValueError as e:\n",
    "        print(t)\n",
    "        raise e\n",
    "\n",
    "# aliases= yml[table]\n",
    "# format_bo_sql(bo_queries[table], table, schema='stage')\n",
    "# omop.execute(format_stage_query('MEASUREMENT_HeartRate'))\n",
    "\n",
    "# aliases = {}\n",
    "# for t in bo_queries.keys():\n",
    "#     with omop.engine.connect() as con:\n",
    "#         cols = pd.read_sql(f\"select top 0 * from stage.{t}\", con)\n",
    "#         aliases[t] = [x.lower() for x in cols.columns]\n",
    "\n",
    "# with open('col_aliases.yml', 'w') as f:\n",
    "#     yaml.dump(aliases, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cast(Flowsheet_BP_CVP.MEASR_VALUE as numeric(10,2))\nFlowsheet_BP_CVP.MEASR_VALUE as numeric(10,2)\n['Flowsheet_BP_CVP.MEASR_VALUE', 'numeric(10,2)']\n"
     ]
    }
   ],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_BP_CVP']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "idx = [parsed.token_index(t) for t in parsed if t.is_keyword and t.value == 'FROM'][0]\n",
    "columns = parsed.token_prev(idx)[1]\n",
    "\n",
    "# Extract columns from SELECT clause. If duplicated columns, use alias, \n",
    "# else append abbreviated source table name.\n",
    "colnames = [i.value.split('.')[-1] for i in columns]\n",
    "dup_cols = set([x for x in colnames if colnames.count(x) > 1])\n",
    "new_colnames = []\n",
    "\n",
    "counter = 0\n",
    "for item in columns:\n",
    "    if isinstance(item, sqlparse.sql.Identifier):\n",
    "        colname = item.value.split('.')[-1]\n",
    "        tabname = item.value.split('.')[-2]\n",
    "        shrt_tabname = '_'.join([word[:3] for word in tabname.split('_')])\n",
    "        # print('Identifier', item.value)\n",
    "    \n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        counter += 1\n",
    "        fn_name = f'FN_{counter}'\n",
    "        for x in item:\n",
    "            if (isinstance(x, sqlparse.sql.Identifier) and x.value == 'cast'):\n",
    "                print(item.value)\n",
    "                continue\n",
    "            else: \n",
    "                pass\n",
    "            if isinstance(x, sqlparse.sql.Parenthesis): \n",
    "                for y in x:\n",
    "                    if isinstance(y, sqlparse.sql.Identifier):\n",
    "                        print(y.value)\n",
    "                        print([i.strip() for i in y.value.split(' as ')])\n",
    "                        # col, dtype = [i.strip() for i in y.value.split('as')]\n",
    "                        # print(f'try_convert({dtype}, {col})')\n",
    "    \n",
    "    # else: \n",
    "    #     print('Something else', item.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dbo.ALL_PATIENTS.PATNT_KEY,  PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY,  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE,  Flowsheet_HTandWT_Height.MEASR_TAKN_DT,  ( try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) )*2.54,  ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY,  ALL_PROVIDERS_VISIT.PROVIDR_KEY\nWHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( 12345678 )  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE >= '01/01/1900 00:0:0'  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE <= '12/31/1900 00:0:0'  AND  (   ( try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) )*2.54 Is Not Null    OR   try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) Is Not Null   )  AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = 'Complete'  AND  ( dbo.ALL_PATIENTS.TEST_IND='N' )  )\n"
     ]
    }
   ],
   "source": [
    "def flatten(alist):\n",
    "    flat = []\n",
    "    while alist: \n",
    "        e = alist.pop()\n",
    "        if type(e) == list: \n",
    "            alist.extend(e) \n",
    "        else:\n",
    "            flat.append(e) \n",
    "     \n",
    "    return flat\n",
    "\n",
    "# def replace_cast_with_try_convert(parsed):    \n",
    "items = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                \n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                       for p in item if isinstance(p, sqlparse.sql.Parenthesis)])\n",
    "                item.value = f'try_convert({dtype},{col})'\n",
    "                \n",
    "            else:\n",
    "                fun_list = flatten([[a for a in i if isinstance(a, sqlparse.sql.Function)] \n",
    "                                     for i in item if search('cast', i.value)])\n",
    "                \n",
    "                # print(fun_list)\n",
    "                if not fun_list:\n",
    "                    fun_list = [i for i in item if (search('cast', i.value) & isinstance(i, sqlparse.sql.Function))]\n",
    "                \n",
    "                if not fun_list:\n",
    "                    fun_list = flatten(flatten([[[a for a in b if isinstance(a, sqlparse.sql.Function)] \n",
    "                                                for b in i if isinstance(b, sqlparse.sql.Operation)] for i in item if search('cast', i.value)]))\n",
    "\n",
    "                # print(fun_list)\n",
    "                for fun in fun_list:\n",
    "                    col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                           for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                    # print(fun)\n",
    "                    item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "                    # print(item.value)\n",
    "        \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dbo.ALL_PATIENTS.PATNT_KEY,  PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY,  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE,  Flowsheet_HTandWT_Height.MEASR_TAKN_DT,  ( try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) )*2.54,  ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY,  ALL_PROVIDERS_VISIT.PROVIDR_KEY\nWHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( 12345678 )  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE >= '01/01/1900 00:0:0'  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE <= '12/31/1900 00:0:0'  AND  (   ( try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) )*2.54 Is Not Null    OR   try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) Is Not Null   )  AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = 'Complete'  AND  ( dbo.ALL_PATIENTS.TEST_IND='N' )  )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_Height']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight MEASUREMENT_BP_CVP\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "\n",
    "def get_function(item):\n",
    "    if isinstance(item, (sqlparse.sql.Parenthesis, sqlparse.sql.Operation)):\n",
    "        return list(filter(None, [get_function(a) for a in item]))\n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        return item\n",
    "\n",
    "def flatten(lst):\n",
    "    for el in lst:\n",
    "        if isinstance(el, list):  \n",
    "            # recurse\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            # generate\n",
    "            yield el\n",
    " \n",
    "\n",
    "# fun_list = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, (sqlparse.sql.IdentifierList, sqlparse.sql.Where)):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                fun_list = flatten([get_function(item)])\n",
    "                # print(fun_list)\n",
    "\n",
    "            else:\n",
    "                fun_list = flatten(list(filter(None, [get_function(i) for i in item])))\n",
    "                # print(fun_list)\n",
    "\n",
    "            for fun in fun_list:\n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                # print(fun)\n",
    "                item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "    \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[[[<Function 'cast(F...' at 0x2BE606D8EC8>]],\n",
       "  <Function 'cast(F...' at 0x2BE606D89C8>]]"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Flowsheet_BP_CVP.MEASR_VALUE', 'numeric(10,2)']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "reduce(list.__add__, (list(i) for i in [[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<Function 'cast(F...' at 0x2BE60C0E2C8>,\n",
       " <Name 'cast' at 0x2BE605A7E28>,\n",
       " <Punctuation '(' at 0x2BE605A7E88>,\n",
       " <Identifier 'Flowsh...' at 0x2BE60C1C8C8>,\n",
       " <Punctuation ')' at 0x2BE605D31C8>]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "fun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for token in parsed.tokens:\n",
    "#     print(token.ttype)\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        print(token.ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.stage import Stager\n",
    "stage = Stager('config.yml')\n",
    "# print(l.update_mappings('person'))\n",
    "# print(l.update_mappings('visit_occurrence'))\n",
    "\n",
    "# print(l.preload_all())\n",
    "\n",
    "# print(l.load_table('person'))\n",
    "# print(l.load_table('death'))\n",
    "# print(l.load_table('condition_occurrence'))\n",
    "# print(l.load_table('procedure_occurrence'))\n",
    "# print(l.load_table('drug_exposure'))\n",
    "# print(l.load_table('observation'))\n",
    "# print(l.load_table('provider'))\n",
    "# print(l.load_table('care_site'))\n",
    "# print(l.load_table('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conf = stage.store.config_param['load']\n",
    "# stage.stage_table('measurement','res_fio2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no parts person\n",
      "no parts death\n",
      "no parts condition_occurrence\n",
      "has part procedure_occurrence icd\n",
      "has part procedure_occurrence cpt\n",
      "has part drug_exposure order\n",
      "has part drug_exposure admin\n",
      "has part measurement bp\n",
      "has part measurement heart_rate\n",
      "has part measurement height\n",
      "has part measurement lab\n",
      "has part measurement pain\n",
      "has part measurement qtcb\n",
      "has part measurement res_dev\n",
      "has part measurement res_etco2\n",
      "has part measurement res_fio2\n",
      "has part measurement res_gcs\n",
      "has part measurement res_o2\n",
      "has part measurement res_peep\n",
      "has part measurement res_pip\n",
      "has part measurement res_resp\n",
      "has part measurement res_spo2\n",
      "has part measurement res_tidal\n",
      "has part measurement res_vent\n",
      "has part measurement rothman\n",
      "has part measurement sofa\n",
      "has part measurement temp\n",
      "has part measurement weight\n",
      "has part observation icu\n",
      "has part observation lda\n",
      "has part observation vent\n",
      "has part observation payer\n",
      "has part observation smoking\n",
      "has part observation zipcode\n",
      "no parts visit\n"
     ]
    }
   ],
   "source": [
    "for t in load_conf.keys():\n",
    "    if load_conf[t]:\n",
    "        for part in load_conf[t].keys():\n",
    "            stage.stage_table(t, part)\n",
    "    else:\n",
    "        if t not in ('provider','care_site','location'): \n",
    "            stage.stage_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Parenthesis '( dbo...' at 0x2A1B00F7AC8>]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re \n",
    "\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.Where):\n",
    "        print([item for item in token if search('cast', item.value)])\n",
    "\n",
    "        # par = list(itertools.chain(*token))\n",
    "        # for p in par:\n",
    "        #     print(p.__repr__)\n",
    "            # if isinstance(i, sqlparse.sql.Parenthesis):\n",
    "            #     # defs = extract_definitions(i)\n",
    "            #     for x in i:\n",
    "            #         if isinstance(x, sqlparse.sql.Parenthesis):\n",
    "            #             for y in x:\n",
    "            #                 print(y.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    par_level = 0\n",
    "    for token in token_list.flatten():\n",
    "        if token.is_whitespace:\n",
    "            continue\n",
    "        elif token.match(sqlparse.tokens.Punctuation, '('):\n",
    "            par_level += 1\n",
    "            continue\n",
    "        if token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "            if par_level == 0:\n",
    "                break\n",
    "            else:\n",
    "                par_level += 1\n",
    "        elif token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            if tmp:\n",
    "                definitions.append(tmp)\n",
    "            tmp = []\n",
    "        else:\n",
    "            tmp.append(token)\n",
    "    if tmp:\n",
    "        definitions.append(tmp)\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: dbo          DEFINITION: . ALL_PATIENTS . PATNT_KEY IN 12345678 AND Flowsheet_Enc_Dttime_RESP . MEASR_TAKN_DATE >= '01/01/1900 00:0:0' AND cast Flowsheet_RESP_O2_mL . MEASR_VALUE as numeric 10\n",
      "NAME: 2            DEFINITION: Is Not Null OR cast Flowsheet_RESP_O2_Liter . MEASR_VALUE as numeric 10\n",
      "NAME: 2            DEFINITION: Is Not Null AND dbo . ALL_PATIENTS . TEST_IND = 'N'\n"
     ]
    }
   ],
   "source": [
    "for d in defs:\n",
    "    print('NAME: {name!s:12} DEFINITION: {definition}'.format(\n",
    "    name=d[0], definition=' '.join(str(t) for t in d[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "MAPPING = {\n",
    "    'person': 'person_mapping.sql',\n",
    "    'visit_occurrence': 'visit_occurrence_mapping.sql'\n",
    "}\n",
    "\n",
    "PRELOAD = {\n",
    "    'condition_occurrence': 'preload_condition.sql', \n",
    "    'procedure_occurrence': {\n",
    "        'cpt': 'preload_procedure_cpt.sql', \n",
    "        'icd': 'preload_procedure_icd.sql'\n",
    "    },\n",
    "    'drug_exposure': {\n",
    "        'order': 'preload_drug_order.sql', \n",
    "        'admin': 'preload_drug_admin.sql'\n",
    "    }, \n",
    "    'measurement': {\n",
    "        'bp': 'preload_measurement_bp.sql', \n",
    "        'heart_rate': 'preload_measurement_heartrate.sql', \n",
    "        'height': 'preload_measurement_height.sql', \n",
    "        'lab': 'preload_measurement_lab.sql', \n",
    "        'pain': 'preload_measurement_painscale.sql', \n",
    "        'qtcb': 'preload_measurement_qtcb.sql', \n",
    "        'res_dev': 'preload_measurement_res_device.sql', \n",
    "        'res_etco2': 'preload_measurement_res_etco2.sql', \n",
    "        'res_fio2': 'preload_measurement_res_fio2.sql', \n",
    "        'res_gcs': 'preload_measurement_res_gcs.sql', \n",
    "        'res_o2': 'preload_measurement_res_o2.sql', \n",
    "        'res_peep': 'preload_measurement_res_peep.sql', \n",
    "        'res_pip': 'preload_measurement_res_pip.sql', \n",
    "        'res_resp': 'preload_measurement_res_resp.sql', \n",
    "        'res_spo2': 'preload_measurement_res_spo2.sql', \n",
    "        'res_tidal': 'preload_measurement_res_tidal.sql', \n",
    "        'res_vent': 'preload_measurement_res_vent.sql', \n",
    "        'rothman': 'preload_measurement_rothman.sql', \n",
    "        'sofa': 'preload_measurement_sofa.sql', \n",
    "        'temp': 'preload_measurement_temp.sql', \n",
    "        'weight': 'preload_measurement_weight.sql'\n",
    "    }, \n",
    "    'observation': {\n",
    "        'icu': 'preload_observation_icu.sql', \n",
    "        'lda': 'preload_observation_lda.sql', \n",
    "        'vent': 'preload_observation_vent.sql',\n",
    "        'payer': 'preload_observation_payer.sql', \n",
    "        'smoking': 'preload_observation_smoking.sql', \n",
    "        'zipcode': 'preload_observation_zipcode.sql'\n",
    "    }\n",
    "}\n",
    "\n",
    "LOAD = {\n",
    "    'person': 'load_person.sql',\n",
    "    'death': 'load_death.sql',\n",
    "    'visit_occurrence': 'load_visit_occurrence.sql',\n",
    "    'observation_period': 'load_observation_period.sql',\n",
    "    'condition_occurrence': 'load_condition.sql',\n",
    "    'procedure_occurrence': 'load_procedure.sql',\n",
    "    'drug_exposure': 'load_drug_exposure.sql',\n",
    "    'measurement': 'load_measurement.sql',\n",
    "    'observation': 'load_observation.sql',\n",
    "    # Load these tables at the end and in order: provider, care_site, location\n",
    "    'provider': 'load_provider.sql',\n",
    "    'care_site': 'load_care_site.sql',\n",
    "    'location': 'load_location.sql'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('load.yaml','w+') as f:\n",
    "#     yaml.dump(MAPPING, f)\n",
    "#     yaml.dump(PRELOAD, f)\n",
    "#     yaml.dump(LOAD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive Z is SH01\n",
      " Volume Serial Number is B8F7-EF52\n",
      "\n",
      " Directory of Z:\\OMOP\\omop_etl\n",
      "\n",
      "04/06/2021  02:31 PM    <DIR>          .\n",
      "04/06/2021  02:31 PM    <DIR>          ..\n",
      "03/19/2021  10:32 AM               144 .gitignore\n",
      "03/19/2021  01:57 PM    <DIR>          .vscode\n",
      "04/05/2021  10:21 AM             1,809 config.yml\n",
      "02/22/2021  02:23 PM    <DIR>          dist\n",
      "03/12/2021  12:42 PM               842 issues.md\n",
      "02/22/2021  02:23 PM               211 MANIFEST\n",
      "04/06/2021  02:30 PM    <DIR>          notebooks\n",
      "02/24/2021  01:01 PM    <DIR>          omop_etl\n",
      "04/06/2021  02:00 PM            89,945 omop_etl.log\n",
      "02/16/2021  02:18 PM    <DIR>          output\n",
      "03/30/2021  08:50 AM             3,293 README.md\n",
      "01/13/2021  02:56 PM             2,753 readme_yujun.md\n",
      "01/27/2021  12:40 PM                30 requirements.txt\n",
      "04/05/2021  02:39 PM             3,248 run_etl.py\n",
      "02/22/2021  02:49 PM               409 setup.py\n",
      "04/06/2021  02:31 PM             1,086 stage.yaml\n",
      "03/19/2021  10:20 AM    <DIR>          validation\n",
      "              11 File(s)        103,770 bytes\n",
      "               8 Dir(s)  6,428,206,661,632 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('omop_etl/etl_config.yml') as f:\n",
    "        yml = yaml.safe_load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'death': 'load_death.sql',\n",
       " 'drug_exposure': 'load_drug_exposure.sql',\n",
       " 'location': 'load_location.sql',\n",
       " 'measurement': 'load_measurement.sql',\n",
       " 'observation': 'load_observation.sql',\n",
       " 'observation_period': 'load_observation_period.sql',\n",
       " 'person': 'load_person.sql',\n",
       " 'procedure_occurrence': 'load_procedure.sql',\n",
       " 'provider': 'load_provider.sql',\n",
       " 'visit_occurrence': 'load_visit_occurrence.sql'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml['load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0ed9aecc04a78bc023d6560d59868ba438581fdda2914504ea0b1a159872595b9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}