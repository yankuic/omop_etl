{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z:\\Covid19\\Covid19_OMOP\\new_pipeline\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sqlparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "os.chdir('z:/Covid19/Covid19_OMOP/new_pipeline')\n",
    "print(os.getcwd())\n",
    "\n",
    "from omop_etl.datastore import DataStore\n",
    "from omop_etl.load import Loader\n",
    "from omop_etl.utils import search\n",
    "from omop_etl.bo import bo_query, format_stage_query\n",
    "\n",
    "omop = DataStore('config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.config import ProjectConfig, ETLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProjectConfig('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config._config.get('load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = ProjectConfig('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with config.engine.connect() as con:\n",
    "#     print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_config = ETLConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BO Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "omop = DataStore('config.yml')\n",
    "\n",
    "# def format_stage_query(dp_name):\n",
    "\n",
    "#     with open('omop_etl/etl_config.yml') as f:\n",
    "#         yml = yaml.safe_load(f) \n",
    "    \n",
    "#     aliases= yml['aliases'][dp_name]\n",
    "#     bo_queries = omop.get_bo_query('omop')\n",
    "\n",
    "#     start_date = omop.config_param['date_range']['start_date']\n",
    "#     end_date = omop.config_param['date_range']['end_date']\n",
    "\n",
    "#     sql_query = format_bo_sql(bo_queries[dp_name], dp_name, schema='stage', aliases=aliases)\n",
    "#     patient_id = \"select PATIENT_KEY from DWS_OMOP.cohort.PersonList\"\n",
    "#     sql_query = sql_query.replace(\"12345678\", patient_id)\n",
    "#     sql_query = sql_query.replace(\"01/01/1900 00:0:0\", start_date)\n",
    "#     sql_query = sql_query.replace(\"12/31/1900 00:0:0\", end_date)\n",
    "\n",
    "#     sql_query = sqlparse.format(sql_query, reindent_aligned=True, indent_with=1)\n",
    "\n",
    "#     return f\"EXECUTE ('USE [DWS_PROD];\\n {sql_query}')\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BO cohort queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omop_etl.bo import bo_query\n",
    "with omop.engine.connect() as con:\n",
    "    bo_queries = bo_query('omop', con)\n",
    "\n",
    "len(bo_queries.keys())\n",
    "# [q for q in bo_queries.keys() if bo_queries[q] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in bo_queries.keys():\n",
    "    if len(bo_queries[dp]) == 0:\n",
    "        print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing stage_table(measurement, ['res_tidal_spont', True]) ... Done   \n",
      "Elapsed time 00:00:02\n",
      "EXECUTE ('USE DWS_PROD;\n",
      " DROP TABLE IF EXISTS dws_omop.stage.MEASUREMENT_Res_Tidal_Spont;SELECT  dbo.ALL_PATIENTS.PATNT_KEY AS patient_key, PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY AS patnt_encntr_key, Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DATE AS respiratory_date, Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT AS respiratory_datetime, Flowsheet_RESP_TV_SPONT.MEASR_VALUE AS tidal_volume_exhaled, ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY AS attending_provider, ALL_PROVIDERS_VISIT.PROVIDR_KEY AS visit_provider INTO dws_omop.stage.MEASUREMENT_Res_Tidal_Spont  FROM  dbo.ALL_PATIENTS RIGHT OUTER JOIN dbo.ALL_PATIENT_SNAPSHOTS ALL_PT_SNAPSHOTS_ENCOUNTER ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_KEY=dbo.ALL_PATIENTS.PATNT_KEY)  RIGHT OUTER JOIN dbo.PATIENT_ENCOUNTER_DTL ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_SNAPSHT_KEY=dbo.PATIENT_ENCOUNTER_DTL.DSCHRG_PATNT_SNAPSHT_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  LEFT OUTER JOIN dbo.ALL_PROVIDERS ALL_PROVIDERS_ATTENDING ON (dbo.PATIENT_ENCOUNTER_DTL.ATTND_PROVIDR_KEY=ALL_PROVIDERS_ATTENDING.PROVIDR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  FULL OUTER JOIN dbo.ALL_PROVIDER_IDENTITIES ALL_PROVIDER_IDS_ATTEND_SER ON (ALL_PROVIDER_IDS_ATTEND_SER.IDENT_ID_TYPE= -1001\n",
      "  AND ALL_PROVIDERS_ATTENDING.PROVIDR_KEY=ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY AND ALL_PROVIDER_IDS_ATTEND_SER.IDENT_ID_TYPE= -1001)  LEFT OUTER JOIN dbo.PATNT_ENCNTR_KEY_XREF PATNT_ENCNTR_KEY_XREF1 ON (dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  LEFT OUTER JOIN (  SELECT DISTINCT a.LINK_PATNT_ENCNTR_KEY,a.PATNT_ENCNTR_KEY,a.MEASR_TAKN_DT,a.MEASR_TAKN_DATE\n",
      "\n",
      " FROM flowsheet_measure_dtl a join all_flowsheet_measures b on a.flowsht_measr_key=b.flowsht_measr_key\n",
      " where b.ETL_IND = ''Y'' and a.MEASR_VALUE is not null\n",
      " and b.STNDRD_LABEL_CAT is not null  ) Flowsheet_Enc_Dttime ON (dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      "  AND dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=Flowsheet_Enc_Dttime.LINK_PATNT_ENCNTR_KEY)  LEFT OUTER JOIN (  SELECT DISTINCT a.PATNT_ENCNTR_KEY,a.MEASR_TAKN_DT,a.MEASR_TAKN_DATE\n",
      "FROM flowsheet_measure_dtl a join all_flowsheet_measures b on(a.flowsht_measr_key=b.flowsht_measr_key)\n",
      "where b.stndrd_label_cat in(''RESPIRATORY'') and a.measr_value is not null  ) Flowsheet_Enc_Dttime_RESP ON (Flowsheet_Enc_Dttime.PATNT_ENCNTR_KEY=Flowsheet_Enc_Dttime_RESP.PATNT_ENCNTR_KEY AND Flowsheet_Enc_Dttime.MEASR_TAKN_DT=Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT)  LEFT OUTER JOIN (  select a.*\n",
      "\n",
      "from flowsheet_measure_dtl a join all_flowsheet_measures b on (a.flowsht_measr_key=b.flowsht_measr_key)\n",
      "\n",
      " where b.stndrd_label_dtl = ''TIDAL VOLUME SPONT''  ) Flowsheet_RESP_TV_SPONT ON (Flowsheet_RESP_TV_SPONT.PATNT_ENCNTR_KEY=Flowsheet_Enc_Dttime_RESP.PATNT_ENCNTR_KEY and Flowsheet_RESP_TV_SPONT.MEASR_TAKN_DT=Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT)  LEFT OUTER JOIN dbo.ALL_PROVIDERS ALL_PROVIDERS_VISIT ON (dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      "  AND dbo.PATIENT_ENCOUNTER_DTL.VISIT_PROVIDR_KEY=ALL_PROVIDERS_VISIT.PROVIDR_KEY)  WHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( select PATIENT_KEY from dws_omop.cohort.PersonList )  AND  Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DATE >= ''01/01/2012''  AND  Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DATE <= ''12/31/2020''  AND  Flowsheet_RESP_TV_SPONT.MEASR_VALUE Is Not Null   AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = ''Complete''  AND  ( dbo.ALL_PATIENTS.TEST_IND=''N'' )  ) /* User Running = ''Administrator'' ; Document = ''OMOP''; Query = ''MEASUREMENT_Res_Tidal_Spont'' (''DPUNIVERS'') */')\n"
     ]
    }
   ],
   "source": [
    "print(loader.stage_table('measurement', subset='res_tidal_spont', only_query=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT  PX_ALL_PATIENTS.PATNT_KEY,  PX_ALL_PATIENTS.PATNT_ID,  PX_ALL_PATIENT_IDENTITIES.IDENT_ID_INT,  PX_JAX_MRN.IDENT_ID_INT FROM  ALL_PATIENTS PX_ALL_PATIENTS RIGHT OUTER JOIN ALL_PATIENT_SNAPSHOTS PX_ALL_PATIENT_SNAPSHOTS ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_ALL_PATIENTS.PATNT_KEY)  LEFT OUTER JOIN ALL_PATIENT_IDENTITIES PX_ALL_PATIENT_IDENTITIES ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_ALL_PATIENT_IDENTITIES.PATNT_KEY and PX_ALL_PATIENT_IDENTITIES.LOOKUP_IND = 'Y' and PX_ALL_PATIENT_IDENTITIES.IDENT_ID_TYPE = 101)  LEFT OUTER JOIN ALL_PATIENT_IDENTITIES PX_JAX_MRN ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_JAX_MRN.PATNT_KEY and PX_JAX_MRN.LOOKUP_IND = 'Y' and PX_JAX_MRN.IDENT_ID_TYPE = 110)  RIGHT OUTER JOIN PROCEDURE_EVENT_DTL ON (PROCEDURE_EVENT_DTL.PATNT_SNAPSHT_KEY=PX_ALL_PATIENT_SNAPSHOTS.PATNT_SNAPSHT_KEY)  LEFT OUTER JOIN ALL_CPT_PROCEDURE_CODES ON (PROCEDURE_EVENT_DTL.CPT_CD_KEY=ALL_CPT_PROCEDURE_CODES.CPT_CD_KEY)  WHERE  (  PROCEDURE_EVENT_DTL.START_DATE BETWEEN '01/01/2020 00:0:0' AND '12/31/2020 00:0:0'  AND  ALL_CPT_PROCEDURE_CODES.CPT_CD IN ( '87635','U0001','U0002' )  AND  PX_ALL_PATIENT_IDENTITIES.IDENT_ID_INT Is Not Null   AND  ( PX_ALL_PATIENTS.TEST_IND='N' )  ) /* User Running = 'yankuic' ; Document = '21285159'- 'cohort_COVID_Broad'; Query = 'CPT_CodingDetail' ('DPUNIVERS') */\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omop_etl.bo import bo_query\n",
    "with omop.engine.connect() as con:\n",
    "    bo_cohort = bo_query('cohort_COVID_broad', con)\n",
    "\n",
    "table = 'CPT_CodingDetail'\n",
    "# print(format_stage_query(table))\n",
    "bo_cohort[table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.bo import bo_query, format_stage_query\n",
    "import sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTE ('USE DWS_PROD;\n",
      " DROP TABLE IF EXISTS dws_omop.stage.MEASUREMENT_Res_RESP_MechVentSetRate;SELECT DISTINCT  dbo.ALL_PATIENTS.PATNT_KEY, PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY, Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DATE, Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT, Flowsheet_RESP_Mech_Vent.MEASR_VALUE, ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY AS ALL_PRO_IDS_ATT_SER_PROVIDR_KEY, ALL_PROVIDERS_VISIT.PROVIDR_KEY AS ALL_PRO_VIS_PROVIDR_KEY INTO dws_omop.stage.MEASUREMENT_Res_RESP_MechVentSetRate  FROM  dbo.ALL_PATIENTS RIGHT OUTER JOIN dbo.ALL_PATIENT_SNAPSHOTS ALL_PT_SNAPSHOTS_ENCOUNTER ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_KEY=dbo.ALL_PATIENTS.PATNT_KEY)  RIGHT OUTER JOIN dbo.PATIENT_ENCOUNTER_DTL ON (ALL_PT_SNAPSHOTS_ENCOUNTER.PATNT_SNAPSHT_KEY=dbo.PATIENT_ENCOUNTER_DTL.DSCHRG_PATNT_SNAPSHT_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  LEFT OUTER JOIN dbo.ALL_PROVIDERS ALL_PROVIDERS_ATTENDING ON (dbo.PATIENT_ENCOUNTER_DTL.ATTND_PROVIDR_KEY=ALL_PROVIDERS_ATTENDING.PROVIDR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  FULL OUTER JOIN dbo.ALL_PROVIDER_IDENTITIES ALL_PROVIDER_IDS_ATTEND_SER ON (ALL_PROVIDER_IDS_ATTEND_SER.IDENT_ID_TYPE= -1001\n",
      "  AND ALL_PROVIDERS_ATTENDING.PROVIDR_KEY=ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY AND ALL_PROVIDER_IDS_ATTEND_SER.IDENT_ID_TYPE= -1001)  LEFT OUTER JOIN dbo.PATNT_ENCNTR_KEY_XREF PATNT_ENCNTR_KEY_XREF1 ON (dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY AND dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      " )  LEFT OUTER JOIN (  SELECT DISTINCT a.LINK_PATNT_ENCNTR_KEY,a.PATNT_ENCNTR_KEY,a.MEASR_TAKN_DT,a.MEASR_TAKN_DATE\n",
      "\n",
      " FROM flowsheet_measure_dtl a join all_flowsheet_measures b on a.flowsht_measr_key=b.flowsht_measr_key\n",
      " where b.ETL_IND = ''Y'' and a.MEASR_VALUE is not null\n",
      " and b.STNDRD_LABEL_CAT is not null  ) Flowsheet_Enc_Dttime ON (dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      "  AND dbo.PATIENT_ENCOUNTER_DTL.PATNT_ENCNTR_KEY=Flowsheet_Enc_Dttime.LINK_PATNT_ENCNTR_KEY)  LEFT OUTER JOIN (  SELECT DISTINCT a.PATNT_ENCNTR_KEY,a.MEASR_TAKN_DT,a.MEASR_TAKN_DATE\n",
      "FROM flowsheet_measure_dtl a join all_flowsheet_measures b on(a.flowsht_measr_key=b.flowsht_measr_key)\n",
      "where b.stndrd_label_cat in(''RESPIRATORY'') and a.measr_value is not null  ) Flowsheet_Enc_Dttime_RESP ON (Flowsheet_Enc_Dttime.PATNT_ENCNTR_KEY=Flowsheet_Enc_Dttime_RESP.PATNT_ENCNTR_KEY AND Flowsheet_Enc_Dttime.MEASR_TAKN_DT=Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT)  LEFT OUTER JOIN (  select a.*\n",
      "\n",
      " from flowsheet_measure_dtl a join all_flowsheet_measures b on (a.flowsht_measr_key=b.flowsht_measr_key)\n",
      "\n",
      " where b.stndrd_label_dtl = ''RESP RATE - Mech Vent Set Rate''\n",
      "  ) Flowsheet_RESP_Mech_Vent ON (Flowsheet_Enc_Dttime_RESP.PATNT_ENCNTR_KEY=Flowsheet_RESP_Mech_Vent.PATNT_ENCNTR_KEY AND Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT=Flowsheet_RESP_Mech_Vent.MEASR_TAKN_DT)  LEFT OUTER JOIN (  select a.*\n",
      "\n",
      "from flowsheet_measure_dtl a join all_flowsheet_measures b on (a.flowsht_measr_key=b.flowsht_measr_key)\n",
      "\n",
      " where b.stndrd_label_dtl = ''RESP RATE''  ) Flowsheet_RESP_RESPRATE ON (Flowsheet_Enc_Dttime_RESP.PATNT_ENCNTR_KEY=Flowsheet_RESP_RESPRATE.PATNT_ENCNTR_KEY AND Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DT=Flowsheet_RESP_RESPRATE.MEASR_TAKN_DT)  LEFT OUTER JOIN dbo.ALL_PROVIDERS ALL_PROVIDERS_VISIT ON (dbo.PATIENT_ENCOUNTER_DTL.TEST_IND=''N''\n",
      "  AND dbo.PATIENT_ENCOUNTER_DTL.VISIT_PROVIDR_KEY=ALL_PROVIDERS_VISIT.PROVIDR_KEY)  WHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( select PATIENT_KEY from dws_omop.cohort.PersonList )  AND  Flowsheet_Enc_Dttime_RESP.MEASR_TAKN_DATE >= ''01/01/2012''  AND  Flowsheet_RESP_RESPRATE.MEASR_VALUE <= ''12/31/2020''  AND  Flowsheet_RESP_Mech_Vent.MEASR_VALUE\n",
      "  Is Not Null   AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = ''Complete''  AND  ( dbo.ALL_PATIENTS.TEST_IND=''N'' )  ) /* User Running = ''Administrator'' ; Document = ''OMOP''; Query = ''MEASUREMENT_Res_RESP_MechVentSetRate'' (''DPUNIVERS'') */')\n"
     ]
    }
   ],
   "source": [
    "with omop.engine.connect() as con:\n",
    "    print(format_stage_query('omop', 'MEASUREMENT_Res_RESP_MechVentSetRate', '01/01/2012', '12/31/2020', con, schema='stage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo['MEASUREMENT_Res_RESP_MechVentSetRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with omop.engine.connect() as con:\n",
    "#     bo_queries = bo_query('omop', con)\n",
    "# # print(bo_queries.keys())\n",
    "\n",
    "# # SAVE QUERIES TO FILE\n",
    "# for t in bo_queries.keys():\n",
    "#     try:\n",
    "#         print(t)\n",
    "#         f = open(f'./output/sqlstring_{t.lower()}.sql', 'w')\n",
    "#         f.write(format_stage_query(t))\n",
    "#         format_stage_query(t)\n",
    "#         f.close()\n",
    "#     except ValueError as e:\n",
    "#         print(t)\n",
    "#         raise e\n",
    "\n",
    "# aliases= yml[table]\n",
    "# format_bo_sql(bo_queries[table], table, schema='stage')\n",
    "# omop.execute(format_stage_query('MEASUREMENT_HeartRate'))\n",
    "\n",
    "# aliases = {}\n",
    "# for t in bo_queries.keys():\n",
    "#     with omop.engine.connect() as con:\n",
    "#         cols = pd.read_sql(f\"select top 0 * from stage.{t}\", con)\n",
    "#         aliases[t] = [x.lower() for x in cols.columns]\n",
    "\n",
    "# with open('col_aliases.yml', 'w') as f:\n",
    "#     yaml.dump(aliases, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_BP_CVP']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "idx = [parsed.token_index(t) for t in parsed if t.is_keyword and t.value == 'FROM'][0]\n",
    "columns = parsed.token_prev(idx)[1]\n",
    "\n",
    "# Extract columns from SELECT clause. If duplicated columns, use alias, \n",
    "# else append abbreviated source table name.\n",
    "colnames = [i.value.split('.')[-1] for i in columns]\n",
    "dup_cols = set([x for x in colnames if colnames.count(x) > 1])\n",
    "new_colnames = []\n",
    "\n",
    "counter = 0\n",
    "for item in columns:\n",
    "    if isinstance(item, sqlparse.sql.Identifier):\n",
    "        colname = item.value.split('.')[-1]\n",
    "        tabname = item.value.split('.')[-2]\n",
    "        shrt_tabname = '_'.join([word[:3] for word in tabname.split('_')])\n",
    "        # print('Identifier', item.value)\n",
    "    \n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        counter += 1\n",
    "        fn_name = f'FN_{counter}'\n",
    "        for x in item:\n",
    "            if (isinstance(x, sqlparse.sql.Identifier) and x.value == 'cast'):\n",
    "                print(item.value)\n",
    "                continue\n",
    "            else: \n",
    "                pass\n",
    "            if isinstance(x, sqlparse.sql.Parenthesis): \n",
    "                for y in x:\n",
    "                    if isinstance(y, sqlparse.sql.Identifier):\n",
    "                        print(y.value)\n",
    "                        print([i.strip() for i in y.value.split(' as ')])\n",
    "                        # col, dtype = [i.strip() for i in y.value.split('as')]\n",
    "                        # print(f'try_convert({dtype}, {col})')\n",
    "    \n",
    "    # else: \n",
    "    #     print('Something else', item.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(alist):\n",
    "    flat = []\n",
    "    while alist: \n",
    "        e = alist.pop()\n",
    "        if type(e) == list: \n",
    "            alist.extend(e) \n",
    "        else:\n",
    "            flat.append(e) \n",
    "     \n",
    "    return flat\n",
    "\n",
    "# def replace_cast_with_try_convert(parsed):    \n",
    "items = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                \n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                       for p in item if isinstance(p, sqlparse.sql.Parenthesis)])\n",
    "                item.value = f'try_convert({dtype},{col})'\n",
    "                \n",
    "            else:\n",
    "                fun_list = flatten([[a for a in i if isinstance(a, sqlparse.sql.Function)] \n",
    "                                     for i in item if search('cast', i.value)])\n",
    "                \n",
    "                # print(fun_list)\n",
    "                if not fun_list:\n",
    "                    fun_list = [i for i in item if (search('cast', i.value) & isinstance(i, sqlparse.sql.Function))]\n",
    "                \n",
    "                if not fun_list:\n",
    "                    fun_list = flatten(flatten([[[a for a in b if isinstance(a, sqlparse.sql.Function)] \n",
    "                                                for b in i if isinstance(b, sqlparse.sql.Operation)] for i in item if search('cast', i.value)]))\n",
    "\n",
    "                # print(fun_list)\n",
    "                for fun in fun_list:\n",
    "                    col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                           for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                    # print(fun)\n",
    "                    item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "                    # print(item.value)\n",
    "        \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_Height']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight MEASUREMENT_BP_CVP\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "\n",
    "def get_function(item):\n",
    "    if isinstance(item, (sqlparse.sql.Parenthesis, sqlparse.sql.Operation)):\n",
    "        return list(filter(None, [get_function(a) for a in item]))\n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        return item\n",
    "\n",
    "def flatten(lst):\n",
    "    for el in lst:\n",
    "        if isinstance(el, list):  \n",
    "            # recurse\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            # generate\n",
    "            yield el\n",
    " \n",
    "\n",
    "# fun_list = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, (sqlparse.sql.IdentifierList, sqlparse.sql.Where)):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                fun_list = flatten([get_function(item)])\n",
    "                # print(fun_list)\n",
    "\n",
    "            else:\n",
    "                fun_list = flatten(list(filter(None, [get_function(i) for i in item])))\n",
    "                # print(fun_list)\n",
    "\n",
    "            for fun in fun_list:\n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                # print(fun)\n",
    "                item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "    \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce(list.__add__, (list(i) for i in [[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in parsed.tokens:\n",
    "#     print(token.ttype)\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        print(token.ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.stage import Stager\n",
    "stage = Stager('config.yml')\n",
    "# print(l.update_mappings('person'))\n",
    "# print(l.update_mappings('visit_occurrence'))\n",
    "\n",
    "# print(l.preload_all())\n",
    "\n",
    "# print(l.load_table('person'))\n",
    "# print(l.load_table('death'))\n",
    "# print(l.load_table('condition_occurrence'))\n",
    "# print(l.load_table('procedure_occurrence'))\n",
    "# print(l.load_table('drug_exposure'))\n",
    "# print(l.load_table('observation'))\n",
    "# print(l.load_table('provider'))\n",
    "# print(l.load_table('care_site'))\n",
    "# print(l.load_table('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conf = stage.store.config_param['load']\n",
    "# stage.stage_table('measurement','res_fio2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in load_conf.keys():\n",
    "    if load_conf[t]:\n",
    "        for part in load_conf[t].keys():\n",
    "            stage.stage_table(t, part)\n",
    "    else:\n",
    "        if t not in ('provider','care_site','location'): \n",
    "            stage.stage_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re \n",
    "\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.Where):\n",
    "        print([item for item in token if search('cast', item.value)])\n",
    "\n",
    "        # par = list(itertools.chain(*token))\n",
    "        # for p in par:\n",
    "        #     print(p.__repr__)\n",
    "            # if isinstance(i, sqlparse.sql.Parenthesis):\n",
    "            #     # defs = extract_definitions(i)\n",
    "            #     for x in i:\n",
    "            #         if isinstance(x, sqlparse.sql.Parenthesis):\n",
    "            #             for y in x:\n",
    "            #                 print(y.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    par_level = 0\n",
    "    for token in token_list.flatten():\n",
    "        if token.is_whitespace:\n",
    "            continue\n",
    "        elif token.match(sqlparse.tokens.Punctuation, '('):\n",
    "            par_level += 1\n",
    "            continue\n",
    "        if token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "            if par_level == 0:\n",
    "                break\n",
    "            else:\n",
    "                par_level += 1\n",
    "        elif token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            if tmp:\n",
    "                definitions.append(tmp)\n",
    "            tmp = []\n",
    "        else:\n",
    "            tmp.append(token)\n",
    "    if tmp:\n",
    "        definitions.append(tmp)\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check config files\n",
    "\n",
    "- Check tables match in config and etl_config\n",
    "- Check subset names match in config and etl_config\n",
    "- Check dp_names match bo dp_names\n",
    "- Check scripts in etl_config exists\n",
    "- Check all stage tables have aliases\n",
    "- Check aliases match stage table columns\n",
    "- Check load tables match table and subset names\n",
    "- Check load scripts exists\n",
    "- Check table name with source_table\n",
    "- Check source_code from table match source_code from query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\OMOP\\omop_etl\\omop_etl\\templates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('Z:/OMOP/omop_etl/omop_etl/templates')\n",
    "print(os.getcwd())\n",
    "\n",
    "from omop_etl.datastore import DataStore\n",
    "from omop_etl.bo import bo_query\n",
    "from omop_etl.config import ProjectConfig, ETLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'dws_omop'\n",
    "server = 'edw.shands.ufl.edu'\n",
    "\n",
    "omop = DataStore('config.yml')\n",
    "omop.connection_str = f'mssql+pyodbc://{server}/{database}?driver=SQL+Server'\n",
    "\n",
    "with omop.engine.connect() as con:\n",
    "    bo_queries = bo_query('omop', con)\n",
    "\n",
    "_config = ProjectConfig('config.yml')\n",
    "etl_config = ETLConfig()\n",
    "sql_scripts = [os.path.split(p)[1] for p in glob.glob('Z:/OMOP/omop_etl/omop_etl/sql/*.sql') ]\n",
    "\n",
    "path = 'Z:/OMOP/omop_etl/omop_etl/sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_load = _config.load\n",
    "etl_stage = etl_config.stage\n",
    "etl_preload = etl_config.preload\n",
    "etl_mapping = etl_config.mapping\n",
    "etl_load = etl_config.preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(file):\n",
    "    path = 'Z:/OMOP/omop_etl/omop_etl/sql'\n",
    "    filepath = os.path.join(path, file)\n",
    "    \n",
    "    return os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person mapping script exists? True\n",
      "visit_occurrence mapping script exists? True\n",
      "procedure_occurrence, icd load script exists? True\n",
      "procedure_occurrence, icd preload script exists? True\n",
      "procedure_occurrence, cpt load script exists? True\n",
      "procedure_occurrence, cpt preload script exists? True\n",
      "drug_exposure, order load script exists? True\n",
      "drug_exposure, order preload script exists? True\n",
      "drug_exposure, admin load script exists? True\n",
      "drug_exposure, admin preload script exists? True\n",
      "measurement, bp load script exists? True\n",
      "measurement, bp preload script exists? True\n",
      "measurement, bp_artline load script exists? True\n",
      "measurement, bp_artline preload script exists? True\n",
      "measurement, bp_noninvasive load script exists? True\n",
      "measurement, bp_noninvasive preload script exists? True\n",
      "measurement, bp_cvp load script exists? True\n",
      "measurement, bp_cvp preload script exists? True\n",
      "measurement, bp_cvp_mean load script exists? True\n",
      "measurement, bp_cvp_mean preload script exists? True\n",
      "measurement, bp_map_artline load script exists? True\n",
      "measurement, bp_map_artline preload script exists? True\n",
      "measurement, bp_map_cuff load script exists? True\n",
      "measurement, bp_map_cuff preload script exists? True\n",
      "measurement, bp_map_noninvasive load script exists? True\n",
      "measurement, bp_map_noninvasive preload script exists? True\n",
      "measurement, bp_pap_mean load script exists? True\n",
      "measurement, bp_pap_mean preload script exists? True\n",
      "measurement, heart_rate load script exists? True\n",
      "measurement, heart_rate preload script exists? True\n",
      "measurement, height load script exists? True\n",
      "measurement, height preload script exists? True\n",
      "measurement, lab load script exists? True\n",
      "measurement, lab preload script exists? True\n",
      "measurement, pain load script exists? True\n",
      "measurement, pain preload script exists? True\n",
      "measurement, pain_jax load script exists? True\n",
      "measurement, pain_jax preload script exists? True\n",
      "measurement, pain_peds load script exists? True\n",
      "measurement, pain_peds preload script exists? True\n",
      "measurement, qtcb load script exists? True\n",
      "measurement, qtcb preload script exists? True\n",
      "measurement, res_dev load script exists? True\n",
      "measurement, res_dev preload script exists? True\n",
      "measurement, res_etco2 load script exists? True\n",
      "measurement, res_etco2 preload script exists? True\n",
      "measurement, res_etco2_on load script exists? True\n",
      "measurement, res_etco2_on preload script exists? True\n",
      "measurement, res_fio2 load script exists? True\n",
      "measurement, res_fio2 preload script exists? True\n",
      "measurement, gcs load script exists? True\n",
      "measurement, gcs preload script exists? True\n",
      "measurement, gcs_peds load script exists? True\n",
      "measurement, gcs_peds preload script exists? True\n",
      "measurement, res_o2 load script exists? True\n",
      "measurement, res_o2 preload script exists? True\n",
      "measurement, res_o2_ml load script exists? True\n",
      "measurement, res_o2_ml preload script exists? True\n",
      "measurement, res_peep load script exists? True\n",
      "measurement, res_peep preload script exists? True\n",
      "measurement, res_pip load script exists? True\n",
      "measurement, res_pip preload script exists? True\n",
      "measurement, res_resp load script exists? True\n",
      "measurement, res_resp preload script exists? True\n",
      "measurement, res_resp_adultspont load script exists? True\n",
      "measurement, res_resp_adultspont preload script exists? True\n",
      "measurement, res_resp_pedsspont load script exists? True\n",
      "measurement, res_resp_pedsspont preload script exists? True\n",
      "measurement, res_resp_mech load script exists? True\n",
      "measurement, res_resp_mech preload script exists? True\n",
      "measurement, res_spo2 load script exists? True\n",
      "measurement, res_spo2 preload script exists? True\n",
      "measurement, res_tidal load script exists? True\n",
      "measurement, res_tidal preload script exists? True\n",
      "measurement, res_tidal_mech load script exists? True\n",
      "measurement, res_tidal_mech preload script exists? True\n",
      "measurement, res_tidal_spont load script exists? True\n",
      "measurement, res_tidal_spont preload script exists? True\n",
      "measurement, res_vent_mode load script exists? True\n",
      "measurement, res_vent_mode preload script exists? True\n",
      "measurement, res_vent_start load script exists? True\n",
      "measurement, res_vent_start preload script exists? True\n",
      "measurement, res_vent_end load script exists? True\n",
      "measurement, res_vent_end preload script exists? True\n",
      "measurement, res_vent_mode_peds load script exists? True\n",
      "measurement, res_vent_mode_peds preload script exists? True\n",
      "measurement, res_vent_start_peds load script exists? True\n",
      "measurement, res_vent_start_peds preload script exists? True\n",
      "measurement, res_vent_end_peds load script exists? True\n",
      "measurement, res_vent_end_peds preload script exists? True\n",
      "measurement, rothman load script exists? True\n",
      "measurement, rothman preload script exists? True\n",
      "measurement, sofa load script exists? True\n",
      "measurement, sofa preload script exists? True\n",
      "measurement, temp load script exists? True\n",
      "measurement, temp preload script exists? True\n",
      "measurement, weight load script exists? True\n",
      "measurement, weight preload script exists? True\n",
      "observation, icu load script exists? True\n",
      "observation, icu preload script exists? True\n",
      "observation, lda load script exists? True\n",
      "observation, lda preload script exists? True\n",
      "observation, vent load script exists? True\n",
      "observation, vent preload script exists? True\n",
      "observation, payer load script exists? True\n",
      "observation, payer preload script exists? True\n",
      "observation, smoking load script exists? True\n",
      "observation, smoking preload script exists? True\n",
      "observation, zipcode load script exists? True\n",
      "observation, zipcode preload script exists? True\n",
      "provider mapping script exists? True\n",
      "care_site mapping script exists? True\n",
      "location mapping script exists? True\n"
     ]
    }
   ],
   "source": [
    "dp_names = []\n",
    "preload_scripts = []\n",
    "mapping_scripts = []\n",
    "load_scripts = []\n",
    "\n",
    "for table in config_load.keys():\n",
    "    if config_load[table]:\n",
    "        for sbs in config_load[table]:\n",
    "            stg = etl_stage[table]\n",
    "            dp_names.append(etl_stage[table][sbs] if isinstance(stg, dict) else stg)\n",
    "            load_scripts.append(etl_load[table][sbs] if isinstance(stg, dict) else stg)\n",
    "            \n",
    "            if isinstance(stg, dict):\n",
    "                print(f'{table}, {sbs} load script exists?', file_exists(etl_load[table][sbs]))\n",
    "            \n",
    "            if table in etl_preload.keys():\n",
    "                preload_scripts.append(etl_preload[table][sbs])\n",
    "                print(f'{table}, {sbs} preload script exists?', file_exists(etl_preload[table][sbs]))\n",
    "                \n",
    "    else:\n",
    "        if table in etl_stage.keys():\n",
    "            dp_names.append(etl_stage[table])\n",
    "        if table in etl_mapping.keys():\n",
    "            mapping_scripts.append(etl_mapping[table])\n",
    "            print(f'{table} mapping script exists?', file_exists(etl_mapping[table]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dp_names) == set(bo_queries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong dp_name in etl_config\n",
    "set(dp_names) - set(bo_queries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEASUREMENT_Res_RESP_AdultMech', 'MEASUREMENT_Res_RESP_PedsMech'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dp_names missing in etl_config\n",
    "set(bo_queries.keys()) - set(dp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preload table condition_occurrence found in config.\n",
      "Preload table condition_occurrence found in etl_stage\n",
      "Preload table condition_occurrence found in etl_load\n",
      "Preload table drug_exposure found in config.\n",
      "Preload table drug_exposure found in etl_stage\n",
      "Preload table drug_exposure found in etl_load\n",
      "Preload table measurement found in config.\n",
      "Preload table measurement found in etl_stage\n",
      "Preload table measurement found in etl_load\n",
      "Preload table observation found in config.\n",
      "Preload table observation found in etl_stage\n",
      "Preload table observation found in etl_load\n",
      "Preload table procedure_occurrence found in config.\n",
      "Preload table procedure_occurrence found in etl_stage\n",
      "Preload table procedure_occurrence found in etl_load\n"
     ]
    }
   ],
   "source": [
    "# Check if preload tables exist in config, etl stage, and etl load\n",
    "for prl in etl_preload:\n",
    "    if prl in config_load.keys():\n",
    "        print(f'Preload table {prl} found in config.')\n",
    "    if prl in etl_stage.keys():\n",
    "        print(f'Preload table {prl} found in etl_stage')\n",
    "    if prl in etl_load.keys():\n",
    "        print(f'Preload table {prl} found in etl_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = 'Z:/OMOP/omop_etl/omop_etl/templates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv(os.path.join(temp_path, 'source_to_concept_map.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_code</th>\n",
       "      <th>source_concept_id</th>\n",
       "      <th>source_vocabulary_id</th>\n",
       "      <th>source_code_description</th>\n",
       "      <th>target_concept_id</th>\n",
       "      <th>target_vocabulary_id</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXTRAMURAL BIRTH</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM DISASTER SITE</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HMO REFERRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON HEALTHCARE FACILITY</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NONBINARY</td>\n",
       "      <td>8570</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>8521</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>8551</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>MALE</td>\n",
       "      <td>8507</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>8507</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8532</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>8532</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2099-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source_code  source_concept_id source_vocabulary_id  \\\n",
       "0                          ?                  0         Admit Source   \n",
       "1           EXTRAMURAL BIRTH                  0         Admit Source   \n",
       "2         FROM DISASTER SITE                  0         Admit Source   \n",
       "3               HMO REFERRAL                  0         Admit Source   \n",
       "4    NON HEALTHCARE FACILITY                  0         Admit Source   \n",
       "..                       ...                ...                  ...   \n",
       "162                NONBINARY               8570                  Sex   \n",
       "163                    OTHER               8521                  Sex   \n",
       "164                  UNKNOWN               8551                  Sex   \n",
       "165                     MALE               8507                  Sex   \n",
       "166                   FEMALE               8532                  Sex   \n",
       "\n",
       "            source_code_description  target_concept_id target_vocabulary_id  \\\n",
       "0    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "1    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "2    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "3    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "4    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "..                              ...                ...                  ...   \n",
       "162          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "163          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "164          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "165          ALL_SEXES.STNDRD_LABEL               8507               Gender   \n",
       "166          ALL_SEXES.STNDRD_LABEL               8532               Gender   \n",
       "\n",
       "    valid_start_date valid_end_date  \n",
       "0         2020-09-29     2099-12-31  \n",
       "1         2020-09-29     2099-12-31  \n",
       "2         2020-09-29     2099-12-31  \n",
       "3         2020-09-29     2099-12-31  \n",
       "4         2020-09-29     2099-12-31  \n",
       "..               ...            ...  \n",
       "162       2020-09-29     2099-12-31  \n",
       "163       2020-09-29     2099-12-31  \n",
       "164       2020-09-29     2099-12-31  \n",
       "165       2020-09-29     2099-12-31  \n",
       "166       2020-09-29     2099-12-31  \n",
       "\n",
       "[167 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
