{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\OMOP\\omop_etl\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sqlparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "os.chdir('Z:\\OMOP\\omop_etl')\n",
    "print(os.getcwd())\n",
    "\n",
    "from omop_etl.datastore import DataStore\n",
    "from omop_etl.load import Loader\n",
    "from omop_etl.utils import search\n",
    "from omop_etl.bo import bo_query, format_stage_query\n",
    "\n",
    "omop = DataStore('config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.config import ProjectConfig, ETLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProjectConfig('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config._config.get('load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProjectConfig('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlalchemy.engine.base.Connection object at 0x000001BC5007FC88>\n"
     ]
    }
   ],
   "source": [
    "with config.engine.connect() as con:\n",
    "    print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_config = ETLConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BO Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "omop = DataStore('config.yml')\n",
    "\n",
    "def format_stage_query(dp_name):\n",
    "\n",
    "    with open('omop_etl/etl_config.yml') as f:\n",
    "        yml = yaml.safe_load(f) \n",
    "    \n",
    "    aliases= yml['aliases'][dp_name]\n",
    "    bo_queries = omop.get_bo_query('omop')\n",
    "\n",
    "    start_date = omop.config_param['date_range']['start_date']\n",
    "    end_date = omop.config_param['date_range']['end_date']\n",
    "\n",
    "    sql_query = format_bo_sql(bo_queries[dp_name], dp_name, schema='stage', aliases=aliases)\n",
    "    patient_id = \"select PATIENT_KEY from DWS_OMOP.cohort.PersonList\"\n",
    "    sql_query = sql_query.replace(\"12345678\", patient_id)\n",
    "    sql_query = sql_query.replace(\"01/01/1900 00:0:0\", start_date)\n",
    "    sql_query = sql_query.replace(\"12/31/1900 00:0:0\", end_date)\n",
    "\n",
    "    sql_query = sqlparse.format(sql_query, reindent_aligned=True, indent_with=1)\n",
    "\n",
    "    return f\"EXECUTE ('USE [DWS_PROD];\\n {sql_query}')\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO cohort queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omop_etl.bo import bo_query\n",
    "with omop.engine.connect() as con:\n",
    "    bo_queries = bo_query('cohort_COVID_Broad', con)\n",
    "\n",
    "len(bo_queries.keys())\n",
    "# [q for q in bo_queries.keys() if bo_queries[q] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CPT_CodingDetail', 'ICD_CodingDetail', 'Labs_UFHealth', 'Meds_by_name'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo_queries.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo_queries[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT  PX_ALL_PATIENTS.PATNT_KEY,  PX_ALL_PATIENTS.PATNT_ID,  PX_ALL_PATIENT_IDENTITIES.IDENT_ID_INT,  PX_JAX_MRN.IDENT_ID_INT FROM  ALL_PATIENTS PX_ALL_PATIENTS RIGHT OUTER JOIN ALL_PATIENT_SNAPSHOTS PX_ALL_PATIENT_SNAPSHOTS ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_ALL_PATIENTS.PATNT_KEY)  LEFT OUTER JOIN ALL_PATIENT_IDENTITIES PX_ALL_PATIENT_IDENTITIES ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_ALL_PATIENT_IDENTITIES.PATNT_KEY and PX_ALL_PATIENT_IDENTITIES.LOOKUP_IND = 'Y' and PX_ALL_PATIENT_IDENTITIES.IDENT_ID_TYPE = 101)  LEFT OUTER JOIN ALL_PATIENT_IDENTITIES PX_JAX_MRN ON (PX_ALL_PATIENT_SNAPSHOTS.PATNT_KEY=PX_JAX_MRN.PATNT_KEY and PX_JAX_MRN.LOOKUP_IND = 'Y' and PX_JAX_MRN.IDENT_ID_TYPE = 110)  RIGHT OUTER JOIN PROCEDURE_EVENT_DTL ON (PROCEDURE_EVENT_DTL.PATNT_SNAPSHT_KEY=PX_ALL_PATIENT_SNAPSHOTS.PATNT_SNAPSHT_KEY)  LEFT OUTER JOIN ALL_CPT_PROCEDURE_CODES ON (PROCEDURE_EVENT_DTL.CPT_CD_KEY=ALL_CPT_PROCEDURE_CODES.CPT_CD_KEY)  WHERE  (  PROCEDURE_EVENT_DTL.START_DATE BETWEEN '01/01/2020 00:0:0' AND '12/31/2020 00:0:0'  AND  ALL_CPT_PROCEDURE_CODES.CPT_CD IN ( '87635','U0001','U0002' )  AND  PX_ALL_PATIENT_IDENTITIES.IDENT_ID_INT Is Not Null   AND  ( PX_ALL_PATIENTS.TEST_IND='N' )  ) /* User Running = 'yankuic' ; Document = '21285159'- 'cohort_COVID_Broad'; Query = 'CPT_CodingDetail' ('DPUNIVERS') */\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = 'CPT_CodingDetail'\n",
    "# print(format_stage_query(table))\n",
    "bo_queries[table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONDITION\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'format_stage_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8f6774801bc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./output/sqlstring_{t.lower()}.sql'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_stage_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mformat_stage_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'format_stage_query' is not defined"
     ]
    }
   ],
   "source": [
    "with omop.engine.connect() as con:\n",
    "    bo_queries = bo_query('omop', con)\n",
    "# print(bo_queries.keys())\n",
    "\n",
    "# SAVE QUERIES TO FILE\n",
    "for t in bo_queries.keys():\n",
    "    try:\n",
    "        print(t)\n",
    "        f = open(f'./output/sqlstring_{t.lower()}.sql', 'w')\n",
    "        f.write(format_stage_query(t))\n",
    "        format_stage_query(t)\n",
    "        f.close()\n",
    "    except ValueError as e:\n",
    "        print(t)\n",
    "        raise e\n",
    "\n",
    "# aliases= yml[table]\n",
    "# format_bo_sql(bo_queries[table], table, schema='stage')\n",
    "# omop.execute(format_stage_query('MEASUREMENT_HeartRate'))\n",
    "\n",
    "# aliases = {}\n",
    "# for t in bo_queries.keys():\n",
    "#     with omop.engine.connect() as con:\n",
    "#         cols = pd.read_sql(f\"select top 0 * from stage.{t}\", con)\n",
    "#         aliases[t] = [x.lower() for x in cols.columns]\n",
    "\n",
    "# with open('col_aliases.yml', 'w') as f:\n",
    "#     yaml.dump(aliases, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cast(Flowsheet_BP_CVP.MEASR_VALUE as numeric(10,2))\n",
      "Flowsheet_BP_CVP.MEASR_VALUE as numeric(10,2)\n",
      "['Flowsheet_BP_CVP.MEASR_VALUE', 'numeric(10,2)']\n"
     ]
    }
   ],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_BP_CVP']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "idx = [parsed.token_index(t) for t in parsed if t.is_keyword and t.value == 'FROM'][0]\n",
    "columns = parsed.token_prev(idx)[1]\n",
    "\n",
    "# Extract columns from SELECT clause. If duplicated columns, use alias, \n",
    "# else append abbreviated source table name.\n",
    "colnames = [i.value.split('.')[-1] for i in columns]\n",
    "dup_cols = set([x for x in colnames if colnames.count(x) > 1])\n",
    "new_colnames = []\n",
    "\n",
    "counter = 0\n",
    "for item in columns:\n",
    "    if isinstance(item, sqlparse.sql.Identifier):\n",
    "        colname = item.value.split('.')[-1]\n",
    "        tabname = item.value.split('.')[-2]\n",
    "        shrt_tabname = '_'.join([word[:3] for word in tabname.split('_')])\n",
    "        # print('Identifier', item.value)\n",
    "    \n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        counter += 1\n",
    "        fn_name = f'FN_{counter}'\n",
    "        for x in item:\n",
    "            if (isinstance(x, sqlparse.sql.Identifier) and x.value == 'cast'):\n",
    "                print(item.value)\n",
    "                continue\n",
    "            else: \n",
    "                pass\n",
    "            if isinstance(x, sqlparse.sql.Parenthesis): \n",
    "                for y in x:\n",
    "                    if isinstance(y, sqlparse.sql.Identifier):\n",
    "                        print(y.value)\n",
    "                        print([i.strip() for i in y.value.split(' as ')])\n",
    "                        # col, dtype = [i.strip() for i in y.value.split('as')]\n",
    "                        # print(f'try_convert({dtype}, {col})')\n",
    "    \n",
    "    # else: \n",
    "    #     print('Something else', item.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbo.ALL_PATIENTS.PATNT_KEY,  PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY,  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE,  Flowsheet_HTandWT_Height.MEASR_TAKN_DT,  ( try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) )*2.54,  ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY,  ALL_PROVIDERS_VISIT.PROVIDR_KEY\n",
      "WHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( 12345678 )  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE >= '01/01/1900 00:0:0'  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE <= '12/31/1900 00:0:0'  AND  (   ( try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) )*2.54 Is Not Null    OR   try_convert(Flowsheet_HTandWT_Height.MEASR_VALUE,real) Is Not Null   )  AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = 'Complete'  AND  ( dbo.ALL_PATIENTS.TEST_IND='N' )  )\n"
     ]
    }
   ],
   "source": [
    "def flatten(alist):\n",
    "    flat = []\n",
    "    while alist: \n",
    "        e = alist.pop()\n",
    "        if type(e) == list: \n",
    "            alist.extend(e) \n",
    "        else:\n",
    "            flat.append(e) \n",
    "     \n",
    "    return flat\n",
    "\n",
    "# def replace_cast_with_try_convert(parsed):    \n",
    "items = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                \n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                       for p in item if isinstance(p, sqlparse.sql.Parenthesis)])\n",
    "                item.value = f'try_convert({dtype},{col})'\n",
    "                \n",
    "            else:\n",
    "                fun_list = flatten([[a for a in i if isinstance(a, sqlparse.sql.Function)] \n",
    "                                     for i in item if search('cast', i.value)])\n",
    "                \n",
    "                # print(fun_list)\n",
    "                if not fun_list:\n",
    "                    fun_list = [i for i in item if (search('cast', i.value) & isinstance(i, sqlparse.sql.Function))]\n",
    "                \n",
    "                if not fun_list:\n",
    "                    fun_list = flatten(flatten([[[a for a in b if isinstance(a, sqlparse.sql.Function)] \n",
    "                                                for b in i if isinstance(b, sqlparse.sql.Operation)] for i in item if search('cast', i.value)]))\n",
    "\n",
    "                # print(fun_list)\n",
    "                for fun in fun_list:\n",
    "                    col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                           for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                    # print(fun)\n",
    "                    item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "                    # print(item.value)\n",
    "        \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbo.ALL_PATIENTS.PATNT_KEY,  PATNT_ENCNTR_KEY_XREF1.PATNT_ENCNTR_KEY,  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE,  Flowsheet_HTandWT_Height.MEASR_TAKN_DT,  ( try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) )*2.54,  ALL_PROVIDER_IDS_ATTEND_SER.PROVIDR_KEY,  ALL_PROVIDERS_VISIT.PROVIDR_KEY\n",
      "WHERE  (  dbo.ALL_PATIENTS.PATNT_KEY IN ( 12345678 )  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE >= '01/01/1900 00:0:0'  AND  Flowsheet_HTandWT_Height.MEASR_TAKN_DATE <= '12/31/1900 00:0:0'  AND  (   ( try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) )*2.54 Is Not Null    OR   try_convert(real,Flowsheet_HTandWT_Height.MEASR_VALUE) Is Not Null   )  AND  dbo.PATIENT_ENCOUNTER_DTL.CALCULATED_ENCNTR_STAT_DESC = 'Complete'  AND  ( dbo.ALL_PATIENTS.TEST_IND='N' )  )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_Height']#'MEASUREMENT_BP_MAP_Cuff'] or 'MEASUREMENT_Height' MEASUREMENT_Weight MEASUREMENT_BP_CVP\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "\n",
    "def get_function(item):\n",
    "    if isinstance(item, (sqlparse.sql.Parenthesis, sqlparse.sql.Operation)):\n",
    "        return list(filter(None, [get_function(a) for a in item]))\n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        return item\n",
    "\n",
    "def flatten(lst):\n",
    "    for el in lst:\n",
    "        if isinstance(el, list):  \n",
    "            # recurse\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            # generate\n",
    "            yield el\n",
    " \n",
    "\n",
    "# fun_list = []\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, (sqlparse.sql.IdentifierList, sqlparse.sql.Where)):\n",
    "        items = [item for item in token if search('cast', item.value)]\n",
    "        # print(items)\n",
    "        for item in items:\n",
    "            if isinstance(item, sqlparse.sql.Function):\n",
    "                fun_list = flatten([get_function(item)])\n",
    "                # print(fun_list)\n",
    "\n",
    "            else:\n",
    "                fun_list = flatten(list(filter(None, [get_function(i) for i in item])))\n",
    "                # print(fun_list)\n",
    "\n",
    "            for fun in fun_list:\n",
    "                col, dtype = flatten([[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                # print(fun)\n",
    "                item.value = item.value.replace(fun.value, f'try_convert({dtype},{col})')\n",
    "    \n",
    "        token.value = ''.join(item.value for item in token)\n",
    "\n",
    "        print(token.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[<Function 'cast(F...' at 0x2BE606D8EC8>]],\n",
       "  <Function 'cast(F...' at 0x2BE606D89C8>]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flowsheet_BP_CVP.MEASR_VALUE', 'numeric(10,2)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(list.__add__, (list(i) for i in [[i.value.split(' as ') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                        for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Function 'cast(F...' at 0x2BE60C0E2C8>,\n",
       " <Name 'cast' at 0x2BE605A7E28>,\n",
       " <Punctuation '(' at 0x2BE605A7E88>,\n",
       " <Identifier 'Flowsh...' at 0x2BE60C1C8C8>,\n",
       " <Punctuation ')' at 0x2BE605D31C8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for token in parsed.tokens:\n",
    "#     print(token.ttype)\n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        print(token.ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.stage import Stager\n",
    "stage = Stager('config.yml')\n",
    "# print(l.update_mappings('person'))\n",
    "# print(l.update_mappings('visit_occurrence'))\n",
    "\n",
    "# print(l.preload_all())\n",
    "\n",
    "# print(l.load_table('person'))\n",
    "# print(l.load_table('death'))\n",
    "# print(l.load_table('condition_occurrence'))\n",
    "# print(l.load_table('procedure_occurrence'))\n",
    "# print(l.load_table('drug_exposure'))\n",
    "# print(l.load_table('observation'))\n",
    "# print(l.load_table('provider'))\n",
    "# print(l.load_table('care_site'))\n",
    "# print(l.load_table('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conf = stage.store.config_param['load']\n",
    "# stage.stage_table('measurement','res_fio2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no parts person\n",
      "no parts death\n",
      "no parts condition_occurrence\n",
      "has part procedure_occurrence icd\n",
      "has part procedure_occurrence cpt\n",
      "has part drug_exposure order\n",
      "has part drug_exposure admin\n",
      "has part measurement bp\n",
      "has part measurement heart_rate\n",
      "has part measurement height\n",
      "has part measurement lab\n",
      "has part measurement pain\n",
      "has part measurement qtcb\n",
      "has part measurement res_dev\n",
      "has part measurement res_etco2\n",
      "has part measurement res_fio2\n",
      "has part measurement res_gcs\n",
      "has part measurement res_o2\n",
      "has part measurement res_peep\n",
      "has part measurement res_pip\n",
      "has part measurement res_resp\n",
      "has part measurement res_spo2\n",
      "has part measurement res_tidal\n",
      "has part measurement res_vent\n",
      "has part measurement rothman\n",
      "has part measurement sofa\n",
      "has part measurement temp\n",
      "has part measurement weight\n",
      "has part observation icu\n",
      "has part observation lda\n",
      "has part observation vent\n",
      "has part observation payer\n",
      "has part observation smoking\n",
      "has part observation zipcode\n",
      "no parts visit\n"
     ]
    }
   ],
   "source": [
    "for t in load_conf.keys():\n",
    "    if load_conf[t]:\n",
    "        for part in load_conf[t].keys():\n",
    "            stage.stage_table(t, part)\n",
    "    else:\n",
    "        if t not in ('provider','care_site','location'): \n",
    "            stage.stage_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Parenthesis '( dbo...' at 0x2A1B00F7AC8>]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re \n",
    "\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.Where):\n",
    "        print([item for item in token if search('cast', item.value)])\n",
    "\n",
    "        # par = list(itertools.chain(*token))\n",
    "        # for p in par:\n",
    "        #     print(p.__repr__)\n",
    "            # if isinstance(i, sqlparse.sql.Parenthesis):\n",
    "            #     # defs = extract_definitions(i)\n",
    "            #     for x in i:\n",
    "            #         if isinstance(x, sqlparse.sql.Parenthesis):\n",
    "            #             for y in x:\n",
    "            #                 print(y.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    par_level = 0\n",
    "    for token in token_list.flatten():\n",
    "        if token.is_whitespace:\n",
    "            continue\n",
    "        elif token.match(sqlparse.tokens.Punctuation, '('):\n",
    "            par_level += 1\n",
    "            continue\n",
    "        if token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "            if par_level == 0:\n",
    "                break\n",
    "            else:\n",
    "                par_level += 1\n",
    "        elif token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            if tmp:\n",
    "                definitions.append(tmp)\n",
    "            tmp = []\n",
    "        else:\n",
    "            tmp.append(token)\n",
    "    if tmp:\n",
    "        definitions.append(tmp)\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
