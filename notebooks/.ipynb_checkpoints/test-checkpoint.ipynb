{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\OMOP\\omop_etl\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sqlparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "os.chdir('Z:\\OMOP\\omop_etl')\n",
    "print(os.getcwd())\n",
    "\n",
    "from omop_etl.datastore import DataStore, format_bo_sql\n",
    "from omop_etl.load import Loader\n",
    "from omop_etl.utils import search\n",
    "\n",
    "# Generate cohort\n",
    "omop = DataStore('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "omop = DataStore('config.yml')\n",
    "\n",
    "def format_stage_query(dp_name):\n",
    "\n",
    "    with open('omop_etl/stage_config.yml') as f:\n",
    "        yml = yaml.safe_load(f) \n",
    "    \n",
    "    aliases= yml['aliases'][dp_name]\n",
    "    bo_queries = omop.get_bo_query('omop')\n",
    "\n",
    "    start_date = omop.config_param['date_range']['start_date']\n",
    "    end_date = omop.config_param['date_range']['end_date']\n",
    "\n",
    "    sql_query = format_bo_sql(bo_queries[dp_name], dp_name, schema='stage', aliases=aliases)\n",
    "    patient_id = \"select PATIENT_KEY from DWS_OMOP.cohort.PersonList\"\n",
    "    sql_query = sql_query.replace(\"12345678\", patient_id)\n",
    "    sql_query = sql_query.replace(\"01/01/1900 00:0:0\", start_date)\n",
    "    sql_query = sql_query.replace(\"12/31/1900 00:0:0\", end_date)\n",
    "\n",
    "    sql_query = sqlparse.format(sql_query, reindent_aligned=True, indent_with=1)\n",
    "\n",
    "    return f\"EXECUTE ('USE [DWS_PROD];\\n {sql_query}')\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'MEASUREMENT_Res_O2'\n",
    "# print(format_stage_query(table))\n",
    "bo_queries = omop.get_bo_query('omop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CONDITION', 'DEATH', 'DRUG_ADMIN', 'DRUG_ORDER', 'MEASUREMENT_BP', 'MEASUREMENT_HeartRate', 'MEASUREMENT_Height', 'MEASUREMENT_LAB', 'MEASUREMENT_PainScale', 'MEASUREMENT_QTCB', 'MEASUREMENT_Res_Device', 'MEASUREMENT_Res_ETCO2', 'MEASUREMENT_Res_FIO2', 'MEASUREMENT_Res_GCS', 'MEASUREMENT_Res_O2', 'MEASUREMENT_Res_PEEP', 'MEASUREMENT_Res_PIP', 'MEASUREMENT_Res_RESP', 'MEASUREMENT_Res_SPO2', 'MEASUREMENT_Res_Tidal', 'MEASUREMENT_Res_Vent', 'MEASUREMENT_Rothman', 'MEASUREMENT_SOFA', 'MEASUREMENT_Temp', 'MEASUREMENT_Weight', 'OBSERVATION_ICU', 'OBSERVATION_LDA', 'OBSERVATION_Payer', 'OBSERVATION_Smoking', 'OBSERVATION_Vent', 'OBSERVATION_Zipcode', 'PERSON', 'PROCEDURE_CPT', 'PROCEDURE_ICD', 'VISIT'])\n"
     ]
    }
   ],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "print(bo_queries.keys())\n",
    "\n",
    "# for t in bo_queries.keys():\n",
    "#     f = open(f'./output/sqlstring_{t.lower()}.sql', 'w')\n",
    "    # f.write(format_stage_query(t))\n",
    "    # f.close()\n",
    "\n",
    "# aliases= yml[table]\n",
    "# format_bo_sql(bo_queries[table], table, schema='stage')\n",
    "# omop.execute(format_stage_query('MEASUREMENT_HeartRate'))\n",
    "\n",
    "# aliases = {}\n",
    "# for t in bo_queries.keys():\n",
    "#     with omop.engine.connect() as con:\n",
    "#         cols = pd.read_sql(f\"select top 0 * from stage.{t}\", con)\n",
    "#         aliases[t] = [x.lower() for x in cols.columns]\n",
    "\n",
    "# with open('col_aliases.yml', 'w') as f:\n",
    "#     yaml.dump(aliases, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_queries = omop.get_bo_query('omop')\n",
    "sqlstring = bo_queries['MEASUREMENT_Res_O2']\n",
    "parsed = sqlparse.parse(sqlstring)[0]\n",
    "idx = [parsed.token_index(t) for t in parsed if t.is_keyword and t.value == 'FROM'][0]\n",
    "columns = parsed.token_prev(idx)[1]\n",
    "\n",
    "# Extract columns from SELECT clause. If duplicated columns, use alias, \n",
    "# else append abbreviated source table name.\n",
    "colnames = [i.value.split('.')[-1] for i in columns]\n",
    "dup_cols = set([x for x in colnames if colnames.count(x) > 1])\n",
    "new_colnames = []\n",
    "\n",
    "counter = 0\n",
    "for item in columns:\n",
    "    if isinstance(item, sqlparse.sql.Identifier):\n",
    "        colname = item.value.split('.')[-1]\n",
    "        tabname = item.value.split('.')[-2]\n",
    "        shrt_tabname = '_'.join([word[:3] for word in tabname.split('_')])\n",
    "        # print('Identifier', item.value)\n",
    "    \n",
    "    elif isinstance(item, sqlparse.sql.Function):\n",
    "        counter += 1\n",
    "        fn_name = f'FN_{counter}'\n",
    "        for x in item:\n",
    "            if (isinstance(x, sqlparse.sql.Identifier) and x.value == 'cast'):\n",
    "                # print(item.value)\n",
    "                continue\n",
    "            else: \n",
    "                pass\n",
    "            if isinstance(x, sqlparse.sql.Parenthesis): \n",
    "                for y in x:\n",
    "                    if isinstance(y, sqlparse.sql.Identifier):\n",
    "                        col, dtype = [i.strip() for i in y.value.split('as')]\n",
    "                        # print(f'try_convert({dtype}, {col})')\n",
    "    \n",
    "    # else: \n",
    "    #     print('Something else', item.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(alist):\n",
    "    return [i for sbl in alist for i in sbl]\n",
    "\n",
    "def replace_cast_with_try_convert(parsed):    \n",
    "    items = []\n",
    "    for token in parsed.tokens:\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "            items.append([item for item in token if search('cast', item.value)])\n",
    "\n",
    "    for item in flatten(items):\n",
    "        if isinstance(item, sqlparse.sql.Function):\n",
    "            col, dtype = flatten([[i.value.split('as') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                   for p in item if isinstance(p, sqlparse.sql.Parenthesis)])[0]\n",
    "            item.value = f'try_convert({dtype},{col})'\n",
    "        else:\n",
    "            fun_list = flatten([[a for a in i if isinstance(a, sqlparse.sql.Function)] \n",
    "                                 for i in t if search('cast', i.value)])\n",
    "            for fun in fun_list:\n",
    "                col, dtype = flatten([[i.value.split('as') for i in p if isinstance(i, sqlparse.sql.Identifier)] \n",
    "                                       for p in fun if isinstance(p, sqlparse.sql.Parenthesis)][0])\n",
    "                fun.value = f'try_convert({dtype},{col})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cast_with_try_convert(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for tokens in parsed.tokens: \n",
    "    if isinstance(token, sqlparse.sql.IdentifierList) or isinstance(token, sqlparse.sql.Where):\n",
    "        items.append([item for item in token if search('cast', item.value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>],\n",
       " [<Parenthesis '( dbo...' at 0x241371C2D48>]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_etl.stage import Stager\n",
    "stage = Stager('config.yml')\n",
    "# print(l.update_mappings('person'))\n",
    "# print(l.update_mappings('visit_occurrence'))\n",
    "\n",
    "# print(l.preload_all())\n",
    "\n",
    "# print(l.load_table('person'))\n",
    "# print(l.load_table('death'))\n",
    "# print(l.load_table('condition_occurrence'))\n",
    "# print(l.load_table('procedure_occurrence'))\n",
    "# print(l.load_table('drug_exposure'))\n",
    "# print(l.load_table('observation'))\n",
    "# print(l.load_table('provider'))\n",
    "# print(l.load_table('care_site'))\n",
    "# print(l.load_table('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conf = stage.store.config_param['load']\n",
    "# stage.stage_table('measurement','res_fio2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no parts person\n",
      "no parts death\n",
      "no parts condition_occurrence\n",
      "has part procedure_occurrence icd\n",
      "has part procedure_occurrence cpt\n",
      "has part drug_exposure order\n",
      "has part drug_exposure admin\n",
      "has part measurement bp\n",
      "has part measurement heart_rate\n",
      "has part measurement height\n",
      "has part measurement lab\n",
      "has part measurement pain\n",
      "has part measurement qtcb\n",
      "has part measurement res_dev\n",
      "has part measurement res_etco2\n",
      "has part measurement res_fio2\n",
      "has part measurement res_gcs\n",
      "has part measurement res_o2\n",
      "has part measurement res_peep\n",
      "has part measurement res_pip\n",
      "has part measurement res_resp\n",
      "has part measurement res_spo2\n",
      "has part measurement res_tidal\n",
      "has part measurement res_vent\n",
      "has part measurement rothman\n",
      "has part measurement sofa\n",
      "has part measurement temp\n",
      "has part measurement weight\n",
      "has part observation icu\n",
      "has part observation lda\n",
      "has part observation vent\n",
      "has part observation payer\n",
      "has part observation smoking\n",
      "has part observation zipcode\n",
      "no parts visit\n"
     ]
    }
   ],
   "source": [
    "for t in load_conf.keys():\n",
    "    if load_conf[t]:\n",
    "        for part in load_conf[t].keys():\n",
    "            stage.stage_table(t, part)\n",
    "    else:\n",
    "        if t not in ('provider','care_site','location'): \n",
    "            stage.stage_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Parenthesis '( dbo...' at 0x2A1B00F7AC8>]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re \n",
    "\n",
    "for token in parsed.tokens:\n",
    "    if isinstance(token, sqlparse.sql.Where):\n",
    "        print([item for item in token if search('cast', item.value)])\n",
    "\n",
    "        # par = list(itertools.chain(*token))\n",
    "        # for p in par:\n",
    "        #     print(p.__repr__)\n",
    "            # if isinstance(i, sqlparse.sql.Parenthesis):\n",
    "            #     # defs = extract_definitions(i)\n",
    "            #     for x in i:\n",
    "            #         if isinstance(x, sqlparse.sql.Parenthesis):\n",
    "            #             for y in x:\n",
    "            #                 print(y.__repr__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "\n",
    "def extract_definitions(token_list):\n",
    "    # assumes that token_list is a parenthesis\n",
    "    definitions = []\n",
    "    tmp = []\n",
    "    par_level = 0\n",
    "    for token in token_list.flatten():\n",
    "        if token.is_whitespace:\n",
    "            continue\n",
    "        elif token.match(sqlparse.tokens.Punctuation, '('):\n",
    "            par_level += 1\n",
    "            continue\n",
    "        if token.match(sqlparse.tokens.Punctuation, ')'):\n",
    "            if par_level == 0:\n",
    "                break\n",
    "            else:\n",
    "                par_level += 1\n",
    "        elif token.match(sqlparse.tokens.Punctuation, ','):\n",
    "            if tmp:\n",
    "                definitions.append(tmp)\n",
    "            tmp = []\n",
    "        else:\n",
    "            tmp.append(token)\n",
    "    if tmp:\n",
    "        definitions.append(tmp)\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: dbo          DEFINITION: . ALL_PATIENTS . PATNT_KEY IN 12345678 AND Flowsheet_Enc_Dttime_RESP . MEASR_TAKN_DATE >= '01/01/1900 00:0:0' AND cast Flowsheet_RESP_O2_mL . MEASR_VALUE as numeric 10\n",
      "NAME: 2            DEFINITION: Is Not Null OR cast Flowsheet_RESP_O2_Liter . MEASR_VALUE as numeric 10\n",
      "NAME: 2            DEFINITION: Is Not Null AND dbo . ALL_PATIENTS . TEST_IND = 'N'\n"
     ]
    }
   ],
   "source": [
    "for d in defs:\n",
    "    print('NAME: {name!s:12} DEFINITION: {definition}'.format(\n",
    "    name=d[0], definition=' '.join(str(t) for t in d[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
