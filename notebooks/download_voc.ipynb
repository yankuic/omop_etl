{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.errorhandler import NoSuchElementException\n",
    "from datetime import datetime as dt\n",
    "from omop_etl.utils import timeitc\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def athena_driver(username, password, headless=True, download_dir=None):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument('window-size=1680x900')\n",
    "    options.headless = headless\n",
    "    if download_dir:\n",
    "        options.add_experimental_option('prefs', {'download.default_directory': download_dir})\n",
    "    driver = webdriver.Chrome(executable_path='chromedriver.exe', options=options)\n",
    "    driver.set_window_position(0,0)\n",
    "    driver.set_window_size(1200, 1375)\n",
    "    driver.set_page_load_timeout(15)\n",
    "    \n",
    "    driver.get(\"https://athena.ohdsi.org/\")\n",
    "    driver.find_element_by_xpath('/html/body/div/div/div[4]/div[2]/div/div[2]/div[2]/button').click()\n",
    "    driver.find_element_by_xpath('/html/body/div/div/header/nav/div[3]/a').click()\n",
    "    driver.find_element_by_xpath('/html/body/div/div/div[1]/div/div[2]/div/button').click()\n",
    "\n",
    "    main_window = driver.current_window_handle\n",
    "    for handle in driver.window_handles:\n",
    "        if handle != main_window:\n",
    "            popup = handle\n",
    "            driver.switch_to.window(popup)\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"username\"]').send_keys(username)\n",
    "    driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys(password)\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div/div[2]/div/form/section[3]/input[4]').click()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    return driver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_new_vocabulary_file(driver):\n",
    "    driver.get('https://athena.ohdsi.org/search-terms/start')\n",
    "    driver.find_element_by_xpath('/html/body/div/div/header/nav/div[3]/div/a/div[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[3]/div/div/div/a[1]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[2]/a').click()\n",
    "    \n",
    "    # double click on select all to make sure no vocab is selected \n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/table/thead/tr/th[1]/label').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/table/thead/tr/th[1]/label').click()\n",
    "\n",
    "    # Select vocabularies\n",
    "    checkboxes = driver.find_elements_by_css_selector(\"#app > div > div.at-vocabs > div.at-vocabularies > table > tbody > tr\")\n",
    "    with open('omop_vocabularies.yml') as f:\n",
    "        vocabs = yaml.safe_load(f)\n",
    "    \n",
    "    for checkbox in checkboxes:\n",
    "        cls = checkbox.find_element_by_class_name('at-vocabularies__code-td')\n",
    "        if cls.text in vocabs:\n",
    "            checkbox.click()\n",
    "            print(f'Vocabulary {cls.text} was selected')\n",
    "    \n",
    "    datestamp = dt.today().strftime('%m_%d_%Y')\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[1]/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[3]/div[2]/div/div[2]/form/div/div[1]/input').send_keys(f'vocabulary_5x_{datestamp}')\n",
    "    \n",
    "    # Request vocab file\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[3]/div[2]/div/div[2]/form/div/div[2]/button[1]').click()\n",
    "\n",
    "    #return to main page\n",
    "    driver.get('https://athena.ohdsi.org/search-terms/start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_vocabulary_file(driver, get_last=True, vocabulary_name=None, archive=True, restore=True):\n",
    "    \"\"\"Download most recent vocabulary file.\"\"\"\n",
    "    driver.get('https://athena.ohdsi.org/search-terms/start')\n",
    "    driver.find_element_by_xpath('/html/body/div/div/header/nav/div[3]/div/a/div[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[3]/div/div/div/a[1]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[3]/div').click()\n",
    "    buttons = driver.find_elements_by_class_name(\"react-sanfona-item\")\n",
    "    last = True\n",
    "    archive = False\n",
    "    if get_last:\n",
    "        button = buttons[0]\n",
    "        tool = button.find_element_by_class_name('ac-toolbar')\n",
    "        status = tool.text.split()[-1]\n",
    "        if status == 'DOWNLOADSHAREARCHIVE': \n",
    "            driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[1]').click()\n",
    "            if archive:\n",
    "                time.sleep(30)\n",
    "                driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[3]').click()\n",
    "        elif status == 'ARCHIVEDRESTORE':\n",
    "            driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button').click()\n",
    "            time.sleep(2)\n",
    "            tool = button.find_element_by_class_name('ac-toolbar')\n",
    "            status = tool.text.split()[-1]\n",
    "            while status == 'PENDING':\n",
    "                print('Restoring vocabulary, please wait.', end='\\r')\n",
    "                time.sleep(60)\n",
    "                tool = button.find_element_by_class_name('ac-toolbar')\n",
    "                status = tool.text.split()[-1]\n",
    "                if status == 'DOWNLOADSHAREARCHIVE':\n",
    "                    time.sleep(30)\n",
    "                    driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[1]').click()\n",
    "                    print(\"Download started\")\n",
    "                    if archive:\n",
    "                        time.sleep(30)\n",
    "                        driver.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[3]').click()                \n",
    "        elif status == 'PENDING':\n",
    "            print('Restoring vocabulary, try again later.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Athena credentials to login\n",
    "#TODO - get an account that everyone can access.\n",
    "#TODO - request credentials \n",
    "\n",
    "USERNAME = \"yankuic@ufl.edu\"\n",
    "PASSWORD = \"7DSrMx7JNTHaXEM\"\n",
    "path = r'Z:\\OMOP_CDM'\n",
    "athena = athena_driver(USERNAME, PASSWORD, headless=False, download_dir=path)\n",
    "# request_new_vocabulary_file(athena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request_new_vocabulary_file(athena)\n",
    "download_vocabulary_file(athena)\n",
    "# athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[2]/div[1]/ul/li/div/button').click()\n",
    "# athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring vocabulary, try again later.\n"
     ]
    }
   ],
   "source": [
    "# athena.switch_to.window(athena.window_handles[0])\n",
    "athena.get('https://athena.ohdsi.org/search-terms/start')\n",
    "athena.find_element_by_xpath('/html/body/div/div/header/nav/div[3]/div/a/div[2]').click()\n",
    "athena.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[3]/div/div/div/a[1]').click()\n",
    "athena.find_element_by_xpath('//*[@id=\"app\"]/div/header/nav/div[3]/div').click()\n",
    "buttons = athena.find_elements_by_class_name(\"react-sanfona-item\")\n",
    "last = True\n",
    "archive = False\n",
    "if last:\n",
    "    button = buttons[0]\n",
    "    tool = button.find_element_by_class_name('ac-toolbar')\n",
    "    status = tool.text.split()[-1]\n",
    "    if status == 'DOWNLOADSHAREARCHIVE': \n",
    "        athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[1]').click()\n",
    "        if archive:\n",
    "            time.sleep(30)\n",
    "            athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[3]').click()\n",
    "    elif status == 'ARCHIVEDRESTORE':\n",
    "        athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button').click()\n",
    "        time.sleep(2)\n",
    "        tool = button.find_element_by_class_name('ac-toolbar')\n",
    "        status = tool.text.split()[-1]\n",
    "        while status == 'PENDING':\n",
    "            print('Restoring vocabulary, please wait.', end='\\r')\n",
    "            time.sleep(60)\n",
    "            tool = button.find_element_by_class_name('ac-toolbar')\n",
    "            status = tool.text.split()[-1]\n",
    "            if status == 'DOWNLOADSHAREARCHIVE':\n",
    "                time.sleep(30)\n",
    "                athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[1]').click()\n",
    "                print(\"Download started\")\n",
    "                if archive:\n",
    "                    time.sleep(30)\n",
    "                    athena.find_element_by_xpath('//*[@id=\"app\"]/div/div[1]/div[2]/div[1]/div[1]/ul/li/div/button[3]').click()                \n",
    "    elif status == 'PENDING':\n",
    "        print('Restoring vocabulary, try again later.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip vocabulary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\OMOP_CDM\\\\vocabulary_download_v5_{fe78dd5b-1bf6-4e4d-9270-195c4299fd07}_1622566662890.zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "path = r'Z:\\OMOP_CDM'\n",
    "csv_list = glob.glob(path + '/*.zip')\n",
    "last_zip = max(csv_list, key=os.path.getctime)\n",
    "last_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary files were extracted.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(last_zip) as z:\n",
    "    z.extractall(path + '/Vocabulary_v5x')\n",
    "    print('Vocabulary files were extracted.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Downloading CPT4 codes\n",
    "OHDSI script to download cpt4 codes does not work anymore. \n",
    "We'll need to wait the update or download the codes by our own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import vocabulary tables into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import time\n",
    "# import math\n",
    "# from pydma.utils import timeit_context\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import numpy.ma as ma\n",
    "# from turbodbc import connect\n",
    "# from turbodbc.exceptions import DatabaseError, InterfaceError\n",
    "# from pydma.databases import OneFLDb\n",
    "\n",
    "# database='DWS_CC_OMOP'\n",
    "# omop = OneFLDb('edw', database=database)\n",
    "# today = datetime.datetime.today()\n",
    "# date_flag = today.strftime('%Y%m%d')\n",
    "# schema = 'xref'\n",
    "\n",
    "# t_connection = connect(driver='{SQL Server}', server='edw.***REMOVED***.edu', \n",
    "#               database=database, trusted_connection='yes')\n",
    "\n",
    "# tables = ['concept']#, 'concept_ancestor','concept_class', 'concept_relationship', 'concept_synonym',\n",
    "# #           'domain', 'drug_strength', 'relationship', 'vocabulary']\n",
    "# df_debug = ''\n",
    "\n",
    "# for table in tables:\n",
    "#     # Truncate table\n",
    "#     cursor = t_connection.cursor()\n",
    "    \n",
    "#     sql = \"\"\"\\\n",
    "#         truncate table {}.{}\n",
    "#         \"\"\".format(schema, table)\n",
    "    \n",
    "#     # Use raw_connection to access data types.\n",
    "#     raw_connection = omop.engine.raw_connection()\n",
    "#     omop_cursor = raw_connection.cursor()\n",
    "#     omop_cursor.execute(sql)\n",
    "#     omop_cursor.commit()\n",
    "          \n",
    "#     # Retrieve sql data types \n",
    "#     omop_cursor.execute(f'select top 1 * from {schema}.{table}')\n",
    "#     dtypes = {t[0]:t[1] for t in omop_cursor.description}\n",
    "# #     nullable = [t[0] for t in omop_cursor.description if t[-1]]\n",
    "#     omop_cursor.close()\n",
    "#     raw_connection.close()\n",
    "    \n",
    "#     # Use turbodbc supported data types\n",
    "#     for t in dtypes.keys():\n",
    "#         if dtypes[t] is int:\n",
    "#             dtypes[t] = np.int64\n",
    "    \n",
    "#     if table == 'drug_strength':\n",
    "#         chunks = pd.read_csv(r'z:\\OMOP_CDM\\Vocabulary_v5x\\{}.csv'.format(table.upper()), #keep_default_na=False, \n",
    "#                              chunksize=1000000, sep='\\t', dtype=str, low_memory=False)\n",
    "\n",
    "#     else:\n",
    "#         chunks = pd.read_csv(r'z:\\OMOP_CDM\\Vocabulary_v5x\\{}.csv'.format(table.upper()), keep_default_na=False,\n",
    "#                          chunksize=1000000, dtype=dtypes, sep='\\t')\n",
    "    \n",
    "#     insert_query = \"\"\"\n",
    "#             SET ANSI_WARNINGS OFF\n",
    "            \n",
    "#             INSERT INTO {0}.{1} ({2})\n",
    "#             VALUES ({3})\n",
    "            \n",
    "#             SET ANSI_WARNINGS ON\n",
    "#         \"\"\"\n",
    "    \n",
    "#     remove_999 = \"\"\"\n",
    "#             update {0}.{1}\n",
    "#             set {2} = NULL\n",
    "#             where {2} = -999\n",
    "#     \"\"\"\n",
    "    \n",
    "#     count = 0\n",
    "#     rows_proc = 0\n",
    "#     with timeit_context(f'Processing table {table}'):\n",
    "#         print(f'Loading table {table} into schema {schema}. Please wait.')\n",
    "#         for chunk in chunks:\n",
    "            \n",
    "#             if table == 'drug_strength':\n",
    "                \n",
    "#                 for col in chunk.columns:\n",
    "#                     data_type = dtypes[col]\n",
    "#                     if data_type is np.int64:\n",
    "#                         chunk[col] = chunk[col].fillna(-999).astype(data_type)\n",
    "#                     elif data_type is str:\n",
    "#                         chunk[col] = chunk[col].fillna('').astype(data_type)\n",
    "                \n",
    "#             # Replace all NaN for None - turbodbc does not support NaN\n",
    "#             chunk = chunk.where((pd.notnull(chunk)), None)\n",
    "\n",
    "#             if count == 0:\n",
    "#                 columns = ','.join(chunk.columns)\n",
    "#                 n_cols = len(chunk.columns)\n",
    "#                 placehl = ','.join(['?']*n_cols)\n",
    "#                 count=+1\n",
    "\n",
    "#             insert_query = insert_query.format(schema, table, columns, placehl)\n",
    "\n",
    "#             try:\n",
    "#                 cursor.executemanycolumns(insert_query, [np.ascontiguousarray(chunk[col].values) for col in chunk.columns])\n",
    "#                 rows_proc = rows_proc + chunk.shape[0]\n",
    "#                 t_connection.commit()\n",
    "                                \n",
    "#             except (DatabaseError, InterfaceError, ValueError) as e:\n",
    "#                 df_debug = chunk\n",
    "#                 t_connection.rollback()\n",
    "#                 t_connection.close()\n",
    "#                 raise e\n",
    "    \n",
    "#     if table == 'drug_strength':\n",
    "        \n",
    "#         for col in chunk.columns:\n",
    "#             data_type = dtypes[col]\n",
    "#             if data_type is np.int64:\n",
    "#                 print(f'Cleaning up column {col}')\n",
    "#                 cursor.execute(remove_999.format(schema, table, col))\n",
    "#                 t_connection.commit()\n",
    "\n",
    "#     cursor.close()            \n",
    "#     print(f'Import complete: {rows_proc} rows processed')\n",
    "\n",
    "# t_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to import optional dependencies:\n",
      "selenium: No module named 'selenium'\n",
      "Importing drug_strength finished in 00:00:05\n"
     ]
    }
   ],
   "source": [
    "# _BOOLEAN_CODE = 0\n",
    "# _INTEGER_CODE = 10\n",
    "# _FLOATING_POINT_CODE = 20\n",
    "# _STRING_CODE = 30\n",
    "# _UNICODE_CODE = 31\n",
    "# _TIMESTAMP_CODE = 40\n",
    "# _DATE_CODE = 41\n",
    "    \n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "from omop_etl.utils import timeitc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from turbodbc import connect, make_options\n",
    "from turbodbc.exceptions import DatabaseError, InterfaceError\n",
    "from pydma.databases import OneFLDb\n",
    "\n",
    "schema = 'testing'\n",
    "table = 'drug_strength'\n",
    "database = 'dws_omop'\n",
    "omop = OneFLDb('edw', database=database)\n",
    "\n",
    "tbdbc_dtypes = {10: int, 20:np.int64, 30:str}\n",
    "\n",
    "options = make_options(use_async_io=True,\n",
    "                       prefer_unicode=True,\n",
    "                       fetch_wchar_as_char=True)\n",
    "\n",
    "connection = connect(driver='{SQL Server}', server='edw.***REMOVED***.edu', \n",
    "                     database=database, trusted_connection='yes', turbodbc_options=options)\n",
    "\n",
    "#get table data types\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f'select top 1 * from {schema}.{table}')\n",
    "dtypes = {t[0]:t[1] for t in cursor.description}\n",
    "# cursor.close()  \n",
    "\n",
    "for t in dtypes.keys():\n",
    "    if dtypes[t] == 10:\n",
    "        dtypes[t] = np.int64\n",
    "    elif dtypes[t] == 20:\n",
    "        dtypes[t] = float\n",
    "    else:\n",
    "        dtypes[t] = str\n",
    "\n",
    "try:\n",
    "    next(pd.read_csv(f'z:/OMOP_CDM/Vocabulary_v5x/{table.upper()}.csv', chunksize=1000, dtype=dtypes, sep='\\t'))\n",
    "    \n",
    "    chunks = pd.read_csv(f'z:/OMOP_CDM/Vocabulary_v5x/{table.upper()}.csv', keep_default_na=False,\n",
    "                     chunksize=100000, dtype=dtypes, sep='\\t')\n",
    "except ValueError as e:\n",
    "    chunks = pd.read_csv(f'z:/OMOP_CDM/Vocabulary_v5x/{table.upper()}.csv', chunksize=100000, keep_default_na=False, dtype=str, sep='\\t')\n",
    "\n",
    "\n",
    "count = 0\n",
    "for chunk in chunks:\n",
    "    if count == 0:\n",
    "        columns = ','.join(chunk.columns)\n",
    "        n_cols = len(chunk.columns)\n",
    "        placehl = ','.join(['?']*n_cols)\n",
    "        count=+1\n",
    "\n",
    "    else: break\n",
    "        \n",
    "chunk = chunk.where(pd.notnull(chunk.replace('', np.nan)), None)\n",
    "\n",
    "insert_query = f\"\"\"\n",
    "        set ansi_warnings off; \n",
    "        insert into {schema}.{table} ({columns})\n",
    "        values ({placehl})\n",
    "        set ansi_warnings on\n",
    "    \"\"\"\n",
    "\n",
    "truncate_str = f'truncate table {schema}.{table}'\n",
    "cursor.execute(truncate_str)\n",
    "connection.commit()\n",
    "\n",
    "with timeitc(f'Importing {table}'):\n",
    "    cursor.executemanycolumns(insert_query, [np.ascontiguousarray(chunk[col].values) for col in chunk.columns])\n",
    "    connection.commit()\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loinc = pd.read_csv('/OMOP/omop_etl/xref/loinc.csv', sep='\\t')\n",
    "# source_to_concept = loinc = pd.read_csv('/OMOP/omop_etl/xref/source_to_concept_map.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with omop.engine.connect() as con:\n",
    "#     loinc.to_sql('loinc', con, schema='xref', index=False, if_exists='append')\n",
    "#     source_to_concept.to_sql('source_to_concept_map', con, schema='xref', index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# truncate_str = f'truncate table {schema}.{table}'\n",
    "# cursor.execute(truncate_str)\n",
    "# connection.commit()\n",
    "    \n",
    "# with timeitc(f'Importing {table}'):\n",
    "#     with omop.engine.connect() as con:\n",
    "#         chunk.to_sql(table, con, schema='testing', index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omop_etl.io import import_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table concept, please wait\n",
      "\n",
      "Processing table concept_ancestor, please wait\n",
      "\n",
      "Processing table concept_class, please wait\n",
      "\n",
      "Processing table concept_relationship, please wait\n",
      "\n",
      "Processing table concept_synonym, please wait\n",
      "\n",
      "Processing table domain, please wait\n",
      "\n",
      "Processing table drug_strength, please wait\n",
      "\n",
      "Processing table relationship, please wait\n",
      "\n",
      "Processing table vocabulary, please wait\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = 'testing'\n",
    "# table = 'concept'\n",
    "database = 'dws_omop'\n",
    "server='edw.***REMOVED***.edu'\n",
    "project_dir = 'z:/OMOP_CDM/Vocabulary_v5x/'\n",
    "\n",
    "tables = ['concept', 'concept_ancestor','concept_class', 'concept_relationship', 'concept_synonym',\n",
    "          'domain', 'drug_strength', 'relationship', 'vocabulary']\n",
    "\n",
    "for table in tables:\n",
    "    filepath = os.path.join(project_dir, f'{table.upper()}.csv')\n",
    "    print(\n",
    "        f'Processing table {table}, please wait\\n'#,\n",
    "#         import_csv(filepath, table, 1e6, schema, \n",
    "#                    server, database, keep_default_na=False, sep='\\t')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "schema = 'testing'\n",
    "# table = 'concept'\n",
    "database = 'dws_omop'\n",
    "server='edw.***REMOVED***.edu'\n",
    "project_dir = 'z:/OMOP_CDM/Vocabulary_v5x/'\n",
    "\n",
    "tables = ['concept', 'concept_ancestor','concept_class', 'concept_relationship', 'concept_synonym',\n",
    "          'domain', 'drug_strength', 'relationship', 'vocabulary']\n",
    "\n",
    "for table in tables:\n",
    "    filepath = os.path.join(project_dir, f'{table.upper()}.csv')\n",
    "    print(\n",
    "        f'Processing table {table}, please wait\\n'#,\n",
    "#         import_csv(filepath, table, 1e6, schema, \n",
    "#                    server, database, keep_default_na=False, sep='\\t')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Z:/OMOP/omop_etl/omop_etl/templates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stcm = pd.read_csv(os.path.join(path, 'source_to_concept_map.csv'), sep='\\t')\n",
    "stcm['invalid_reason'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcm.to_csv(os.path.join(path, 'SOURCE_TO_CONCEPT_MAP.csv'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_code</th>\n",
       "      <th>source_concept_id</th>\n",
       "      <th>source_vocabulary_id</th>\n",
       "      <th>source_code_description</th>\n",
       "      <th>target_concept_id</th>\n",
       "      <th>target_vocabulary_id</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXTRAMURAL BIRTH</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM DISASTER SITE</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HMO REFERRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON HEALTHCARE FACILITY</td>\n",
       "      <td>0</td>\n",
       "      <td>Admit Source</td>\n",
       "      <td>ALL_ADMIT_SOURCES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NONBINARY</td>\n",
       "      <td>8570</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>8521</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>8551</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>MALE</td>\n",
       "      <td>8507</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>8507</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8532</td>\n",
       "      <td>Sex</td>\n",
       "      <td>ALL_SEXES.STNDRD_LABEL</td>\n",
       "      <td>8532</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source_code  source_concept_id source_vocabulary_id  \\\n",
       "0                          ?                  0         Admit Source   \n",
       "1           EXTRAMURAL BIRTH                  0         Admit Source   \n",
       "2         FROM DISASTER SITE                  0         Admit Source   \n",
       "3               HMO REFERRAL                  0         Admit Source   \n",
       "4    NON HEALTHCARE FACILITY                  0         Admit Source   \n",
       "..                       ...                ...                  ...   \n",
       "158                NONBINARY               8570                  Sex   \n",
       "159                    OTHER               8521                  Sex   \n",
       "160                  UNKNOWN               8551                  Sex   \n",
       "161                     MALE               8507                  Sex   \n",
       "162                   FEMALE               8532                  Sex   \n",
       "\n",
       "            source_code_description  target_concept_id target_vocabulary_id  \\\n",
       "0    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "1    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "2    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "3    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "4    ALL_ADMIT_SOURCES.STNDRD_LABEL                  0                Visit   \n",
       "..                              ...                ...                  ...   \n",
       "158          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "159          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "160          ALL_SEXES.STNDRD_LABEL                  0               Gender   \n",
       "161          ALL_SEXES.STNDRD_LABEL               8507               Gender   \n",
       "162          ALL_SEXES.STNDRD_LABEL               8532               Gender   \n",
       "\n",
       "    valid_start_date invalid_reason  \n",
       "0         2020-09-29                 \n",
       "1         2020-09-29                 \n",
       "2         2020-09-29                 \n",
       "3         2020-09-29                 \n",
       "4         2020-09-29                 \n",
       "..               ...            ...  \n",
       "158       2020-09-29                 \n",
       "159       2020-09-29                 \n",
       "160       2020-09-29                 \n",
       "161       2020-09-29                 \n",
       "162       2020-09-29                 \n",
       "\n",
       "[163 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stcm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
